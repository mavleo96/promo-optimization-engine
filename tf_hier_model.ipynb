{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/brand_segment_mapping_hackathon.xlsx\n",
      "data/macro_data.xlsx\n",
      "data/maximum_discount_constraint_hackathon.xlsx\n",
      "data/sales_data_hackathon.xlsx\n",
      "data/volume_variation_constraint_hackathon.xlsx\n",
      "data/submission_template_hackathon.csv\n"
     ]
    }
   ],
   "source": [
    "# !pip install azure-storage-blob\n",
    "# !pip install python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from setup_utils import fetch_data, load_data, create_time_index\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CONNECTION_STRING = os.getenv(\"CONNECTION_STRING\")\n",
    "\n",
    "load_dotenv()\n",
    "fetch_data(CONNECTION_STRING)\n",
    "\n",
    "(\n",
    "    brand_mapping_backup,\n",
    "    macro_data_backup,\n",
    "    brand_constraint_backup,\n",
    "    pack_constraint_backup,\n",
    "    segment_constraint_backup,\n",
    "    sales_data_backup,\n",
    "    volume_variation_constraint_backup,\n",
    ") = load_data()\n",
    "\n",
    "(\n",
    "    macro_data_backup,\n",
    "    sales_data_backup,\n",
    ") = create_time_index([macro_data_backup, sales_data_backup])\n",
    "\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_mapping = brand_mapping_backup.copy(deep=True)\n",
    "macro_data = macro_data_backup.copy(deep=True)\n",
    "brand_constraint = brand_constraint_backup.copy(deep=True)\n",
    "pack_constraint = pack_constraint_backup.copy(deep=True)\n",
    "segment_constraint = segment_constraint_backup.copy(deep=True)\n",
    "sales_data = sales_data_backup.copy(deep=True)\n",
    "volume_variation_constraint = volume_variation_constraint_backup.copy(deep=True)\n",
    "\n",
    "sales_index = sales_data.index.unique()\n",
    "macro_data = macro_data.loc[sales_index, ['retail_sales_index', 'unemployment_rate', 'cpi', 'gross_domestic_saving',]].sort_index()\n",
    "covid = pd.Series([1 if (i<=datetime(2020,5,1) and i>=datetime(2020,3,1)) else 0 for i in macro_data.index], index=sales_index, name=\"covid\")\n",
    "macro_data = macro_data.join(covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_dict = {\n",
    "    \"brand\" : brand_constraint,\n",
    "    \"pack\" : pack_constraint,\n",
    "    \"segment\" : segment_constraint,\n",
    "    \"volume_variation\" : volume_variation_constraint\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = sales_data[sales_data.gto.isna()].reset_index()\n",
    "temp_data[\"month\"] = temp_data.date.dt.month\n",
    "temp_data[\"year\"] = temp_data.date.dt.year\n",
    "temp_data = temp_data.fillna(10000)\n",
    "temp_data = temp_data.merge(brand_mapping)\n",
    "\n",
    "master_mapping = temp_data[[\"sku\", \"pack\", \"brand\", \"segment\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_encodings(master_map):\n",
    "\n",
    "    def label_encoder(series):\n",
    "        unique_values = series.sort_values().unique()\n",
    "        unique_count =  series.nunique()\n",
    "\n",
    "        return dict(zip(unique_values, range(len(unique_values))))\n",
    "\n",
    "    def mapper(col_val, col_key=\"sku\"):\n",
    "\n",
    "        df = master_map[[col_key, col_val]].drop_duplicates()\n",
    "        df.loc[:,col_val] = df[col_val].map(label_dict[col_val])\n",
    "        df.loc[:,col_key] = df[col_key].map(label_dict[col_key])\n",
    "\n",
    "        return df.set_index(col_key).to_dict()[col_val]\n",
    "\n",
    "    label_dict = {col:label_encoder(master_map[col]) for col in master_map.columns}\n",
    "    mapper_dict = {col:mapper(col) for col in master_map.columns if col!=\"sku\"}\n",
    "\n",
    "    return {\"label_dict\" : label_dict, \"mapper_dict\" : mapper_dict}\n",
    "\n",
    "final_encodings = _create_encodings(master_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sku_list = np.sort(sales_data.sku.unique()).tolist()\n",
    "target_sku_list = list(final_encodings[\"label_dict\"][\"sku\"].keys())\n",
    "non_target_sku_list = [i for i  in total_sku_list if i not in final_encodings[\"label_dict\"][\"sku\"]]\n",
    "sku_index_order = [*target_sku_list, *non_target_sku_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _constraint_tensor_generate(constraint, encoding, key):\n",
    "\n",
    "    encoding_length = max(encoding[\"label_dict\"][key].values())+1\n",
    "    constraint = constraint.copy(deep=True)\n",
    "    constraint = constraint.replace(encoding[\"label_dict\"][key]).sort_values([\"month\", key])\n",
    "    constraint = constraint.groupby([\"month\", key]).max_discount.sum().sort_index().unstack(1)\n",
    "\n",
    "    constraint = pd.DataFrame(columns=pd.Index(range(0,encoding_length), dtype='int64', name=\"brand\"), index=pd.Index(range(6,8), dtype='int64')).fillna(constraint).fillna(0.0).to_numpy()\n",
    "\n",
    "    return constraint\n",
    "\n",
    "brand_constraint_tensor = _constraint_tensor_generate(constraints_dict[\"brand\"], final_encodings, \"brand\")\n",
    "pack_constraint_tensor = _constraint_tensor_generate(constraints_dict[\"pack\"], final_encodings, \"pack\")\n",
    "segment_constraint_tensor = _constraint_tensor_generate(constraints_dict[\"segment\"], final_encodings, \"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data = macro_data.loc[sales_index].sort_index()\n",
    "macro_data = (macro_data/macro_data.mean()-1).copy(deep=True)\n",
    "macro_data = macro_data.astype(np.float64).values\n",
    "macro_data = np.expand_dims(macro_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_data = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])\n",
    "    .net_revenue.sum()\n",
    "    .sort_index()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    "    .clip(0.0, None)\n",
    "    .fillna(0.0)\n",
    "    .astype(np.float64)\n",
    "    .values\n",
    ")\n",
    "nr_data_mask = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])\n",
    "    .net_revenue.sum()\n",
    "    .sort_index()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    "    .applymap(lambda x: x if x>=0 else np.nan)\n",
    "    .notna()\n",
    "    .astype(np.float64)\n",
    "    .values\n",
    ")\n",
    "\n",
    "nr_shifted = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])\n",
    "    .net_revenue.sum()\n",
    "    .sort_index()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    "    .applymap(lambda x: x if x>=0 else np.nan)\n",
    "    .clip(0.0, None)\n",
    "    .shift(1)\n",
    "    .fillna(method=\"bfill\")\n",
    "    .fillna(0.0)\n",
    "    .astype(np.float64)\n",
    "    .values\n",
    ")\n",
    "\n",
    "volume_data = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])\n",
    "    .volume.sum()\n",
    "    .sort_index()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    "    .clip(0.0, None)\n",
    "    .fillna(0.0)\n",
    "    .astype(np.float64)\n",
    "    .values\n",
    ")\n",
    "\n",
    "\n",
    "discount_data = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])[[\"promotional_discount\", \"other_discounts\"]].sum()\n",
    "    .sort_index()\n",
    "    .stack()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    "    .fillna(0.0)\n",
    "    .clip(None, 0)\n",
    ")\n",
    "discount_data = np.swapaxes(discount_data.astype(np.float64).values.reshape(55,2,discount_data.shape[1]), 1, 2)\n",
    "\n",
    "nr_shifted[-1, :] = nr_shifted[-2, :]\n",
    "nr_shifted = nr_shifted.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = nr_data.mean()\n",
    "vol_scaler = volume_data.mean()\n",
    "\n",
    "nr_data = nr_data/scaler\n",
    "discount_data = discount_data/scaler\n",
    "nr_shifted = nr_shifted/scaler\n",
    "brand_constraint_tensor = brand_constraint_tensor/scaler\n",
    "pack_constraint_tensor = pack_constraint_tensor/scaler\n",
    "segment_constraint_tensor = segment_constraint_tensor/scaler\n",
    "\n",
    "volume_data = volume_data/vol_scaler\n",
    "\n",
    "nr_shifted = np.expand_dims(nr_shifted/nr_shifted.mean(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index_array = np.expand_dims(np.arange(1, macro_data.shape[0]+1), 1)/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "num_splitter = 40\n",
    "\n",
    "y = tf.constant(nr_data[:num_splitter], dtype=tf.float64)\n",
    "y_mask = tf.constant(nr_data_mask[:num_splitter], dtype=tf.float64)\n",
    "\n",
    "discounts = tf.constant(discount_data[:num_splitter], dtype=tf.float64)\n",
    "mixed_effect = tf.constant(macro_data[:num_splitter], dtype=tf.float64)\n",
    "time_index = tf.constant(np.expand_dims(np.arange(1, macro_data.shape[0]+1), 1)[:num_splitter]/400, dtype=tf.float64)\n",
    "shifted_nr = tf.constant(nr_shifted[:num_splitter], dtype=tf.float64)\n",
    "y_vol = tf.constant(volume_data[:num_splitter], dtype=tf.float64)\n",
    "\n",
    "val_splitter_ = tf.constant(5, dtype=tf.int32)\n",
    "val_splitter = 3 #if val_splitter_ == 5 else 2\n",
    "\n",
    "\n",
    "initial_discount_var = tf.constant(discount_data[-2:], dtype=tf.float64)\n",
    "mixed_effect_var = tf.constant(macro_data[-2:], dtype=tf.float64)\n",
    "time_index_var = tf.constant(np.expand_dims(np.arange(1, macro_data.shape[0]+1), 1)[-2:]/400, dtype=tf.float64)\n",
    "y_mask_var = tf.constant(nr_data_mask[-2:], dtype=tf.float64)\n",
    "shifted_nr_var = tf.constant(nr_shifted[-2:], dtype=tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "#Y\n",
    "y = tf.compat.v1.placeholder(dtype=tf.float64, name=\"nr_actual\")\n",
    "y_mask = tf.compat.v1.placeholder(dtype=tf.float64, name=\"nr_mask\")\n",
    "\n",
    "# X\n",
    "discounts = tf.compat.v1.placeholder(dtype=tf.float64, name=\"discounts\")\n",
    "mixed_effect = tf.compat.v1.placeholder(dtype=tf.float64, name=\"mixed_effects\")\n",
    "time_index = tf.compat.v1.placeholder(dtype=tf.float64, name=\"time_index\")\n",
    "shifted_nr = tf.compat.v1.placeholder(dtype=tf.float64, name=\"shifted_nr\")\n",
    "y_vol = tf.compat.v1.placeholder(dtype=tf.float64, name=\"volume_actual\")\n",
    "\n",
    "val_splitter_ = tf.compat.v1.placeholder(dtype=tf.int32)\n",
    "val_splitter = 3 #if val_splitter_ == 5 else 2\n",
    "\n",
    "initial_discount_var = tf.compat.v1.placeholder(dtype=tf.float64, name=\"initial_discount_submit\")\n",
    "\n",
    "mixed_effect_var = tf.compat.v1.placeholder(dtype=tf.float64, name=\"mixed_effect_submit\")\n",
    "time_index_var = tf.compat.v1.placeholder(dtype=tf.float64, name=\"time_index_submit\")\n",
    "y_mask_var = tf.compat.v1.placeholder(dtype=tf.float64, name=\"y_mask_submit\")\n",
    "shifted_nr_var = tf.compat.v1.placeholder(dtype=tf.float64, name=\"shifted_nr_submit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = (1,nr_data.shape[1])\n",
    "me_size = macro_data.shape[-1]\n",
    "\n",
    "baseline_intercept = tf.Variable(np.expand_dims((nr_data.mean(0)*0.3), 0), dtype=tf.float64)\n",
    "\n",
    "baseline_slope1_global = tf.Variable(np.full((1,1), 0.1), dtype=tf.float64)\n",
    "baseline_slope1_hier = tf.Variable(np.full(dim_size, 0.1), dtype=tf.float64)\n",
    "\n",
    "baseline_slope2_global = tf.Variable(np.full((1,1), 0.1), dtype=tf.float64)\n",
    "baseline_slope2_hier = tf.Variable(np.full(dim_size, 0.1), dtype=tf.float64)\n",
    "\n",
    "mixed_effect_mult_global = tf.Variable(np.random.normal(loc=0, size=(1, 1, me_size)), dtype=tf.float64)\n",
    "mixed_effect_mult_hier = tf.Variable(np.random.normal(loc=0, size=(*dim_size, me_size)), dtype=tf.float64)\n",
    "\n",
    "discount_mult_global = tf.math.sigmoid(tf.Variable(np.random.normal(loc=0, size=(1, 1, 2)), dtype=tf.float64))*2\n",
    "discount_mult_hier = tf.math.sigmoid(tf.Variable(np.random.normal(loc=0, size=(*dim_size, 2)), dtype=tf.float64))*2\n",
    "\n",
    "discount_slope_global = tf.math.sigmoid(tf.Variable(np.random.normal(loc=0, size=(1, 1, 2)), dtype=tf.float64))*2\n",
    "discount_slope_hier = tf.math.sigmoid(tf.Variable(np.random.normal(loc=0, size=(*dim_size, 2)), dtype=tf.float64))*2\n",
    "\n",
    "roi_mults_global = tf.Variable(np.random.normal(loc=0, size=(1, 1, me_size)), dtype=tf.float64)\n",
    "roi_mults_hier = tf.Variable(np.random.normal(loc=0, size=(*dim_size, me_size)), dtype=tf.float64)\n",
    "\n",
    "nr_to_vol_slope = tf.Variable(np.random.normal(loc=0, size=dim_size), dtype=tf.float64)\n",
    "nr_to_vol_intercept = tf.Variable(np.random.normal(loc=0, size=dim_size), dtype=tf.float64)\n",
    "\n",
    "hier_var_list = [baseline_slope1_hier, mixed_effect_mult_hier, discount_slope_hier, roi_mults_hier, discount_mult_hier, baseline_slope2_hier]\n",
    "global_var_list = [baseline_slope1_global, mixed_effect_mult_global, discount_slope_global, roi_mults_global, nr_to_vol_slope, nr_to_vol_intercept, discount_mult_global, baseline_slope2_global]\n",
    "\n",
    "discounts_var = tf.Variable(initial_discount_var, dtype=tf.float64)\n",
    "sliced_discount_var = tf.slice(discounts_var, begin=[0,0,0], size=[2,151,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model(\n",
    "        base_intercept_in,\n",
    "        base_slope1_global_in,\n",
    "        base_slope1_hier_in,\n",
    "        base_slope2_global_in,\n",
    "        base_slope2_hier_in,\n",
    "        mixed_effect_mult_global_in,\n",
    "        mixed_effect_mult_hier_in,\n",
    "        discount_mult_global_in,\n",
    "        discount_mult_hier_in,\n",
    "        discount_slope_global_in,\n",
    "        discount_slope_hier_in,\n",
    "        roi_mults_global_in,\n",
    "        roi_mults_hier_in,\n",
    "        nr_to_vol_slope_in,\n",
    "        nr_to_vol_intercept_in,\n",
    "        time_index_in,\n",
    "        mixed_effect_in,\n",
    "        discounts_in,\n",
    "        y_mask_in,\n",
    "        shifted_nr_in\n",
    "    ):\n",
    "    base_slope1_in = base_slope1_global_in + base_slope1_hier_in\n",
    "    base_slope2_in = base_slope2_global_in + base_slope2_hier_in\n",
    "    mixed_effect_mult_in = mixed_effect_mult_global_in + mixed_effect_mult_hier_in\n",
    "    discount_mult_in = discount_mult_global_in + discount_mult_hier_in\n",
    "    discount_slope_in = discount_slope_global_in + discount_slope_hier_in\n",
    "    roi_mults_in = roi_mults_global_in + roi_mults_hier_in\n",
    "\n",
    "    base1_in = tf.multiply(base_slope1_in, time_index_in) + base_intercept_in\n",
    "    base2_in = base1_in + tf.multiply(base_slope2_in, shifted_nr_in)\n",
    "    mixed_effect_impact_in = 1 + tf.nn.tanh(tf.multiply(mixed_effect_in, mixed_effect_mult_in))\n",
    "    total_mixed_effect_impact_in = tf.reduce_prod(mixed_effect_impact_in, axis=-1)\n",
    "    discount_impact_in = tf.multiply(discount_slope_in, tf.math.log1p(tf.multiply(discount_mult_in, tf.nn.relu(-discounts_in))))\n",
    "    roi_mult_impact_in = 1 + tf.nn.tanh(tf.multiply(mixed_effect_impact_in, roi_mults_in))\n",
    "    total_roi_mult_impact_in = tf.expand_dims(tf.reduce_prod(roi_mult_impact_in, axis=-1), axis=-1)\n",
    "\n",
    "    y_pred_out = tf.multiply(\n",
    "        y_mask_in,\n",
    "        (\n",
    "            tf.multiply(base2_in, total_mixed_effect_impact_in)\n",
    "            + tf.reduce_sum(\n",
    "                tf.multiply(discount_impact_in, total_roi_mult_impact_in), axis=-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    y_vol_pred_out = nr_to_vol_intercept_in + tf.multiply(y_pred_out, nr_to_vol_slope_in)\n",
    "\n",
    "    return y_pred_out, y_vol_pred_out\n",
    "\n",
    "@tf.function\n",
    "def wape(y_actual, y_prediction):\n",
    "    return tf.reduce_sum(tf.math.abs(y_actual - y_prediction))/tf.reduce_sum(y_actual)\n",
    "\n",
    "@tf.function\n",
    "def mse(y_actual, y_prediction):\n",
    "    return tf.reduce_sum(tf.math.square(y_actual - y_prediction))\n",
    "\n",
    "@tf.function\n",
    "def _tensor_gather(tensor_to_gather_in, encoding, key):\n",
    "    encoding = pd.Series(encoding[\"mapper_dict\"][key]).sort_index().to_numpy()\n",
    "    segment_ids = tf.constant(encoding, dtype=tf.int32)\n",
    "    x_transpose = tf.transpose(tensor_to_gather_in, perm=[1,0,2])\n",
    "    x_gathered = tf.math.unsorted_segment_sum(x_transpose, segment_ids, num_segments=encoding.max()+1)\n",
    "    x_gathered_transpose = tf.reduce_mean(tf.transpose(x_gathered, perm=[1,0,2]), axis=2)\n",
    "\n",
    "    return x_gathered_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_vol_pred = model(\n",
    "    baseline_intercept,\n",
    "    baseline_slope1_global,\n",
    "    baseline_slope1_hier,\n",
    "    baseline_slope2_global,\n",
    "    baseline_slope2_hier,\n",
    "    mixed_effect_mult_global,\n",
    "    mixed_effect_mult_hier,\n",
    "    discount_mult_global,\n",
    "    discount_mult_hier,\n",
    "    discount_slope_global,\n",
    "    discount_slope_hier,\n",
    "    roi_mults_global,\n",
    "    roi_mults_hier,\n",
    "    nr_to_vol_slope,\n",
    "    nr_to_vol_intercept,\n",
    "    time_index,\n",
    "    mixed_effect,\n",
    "    discounts,\n",
    "    y_mask,\n",
    "    shifted_nr\n",
    ")\n",
    "\n",
    "y_inital_pred, y_initial_vol_pred = model(\n",
    "    baseline_intercept,\n",
    "    baseline_slope1_global,\n",
    "    baseline_slope1_hier,\n",
    "    baseline_slope2_global,\n",
    "    baseline_slope2_hier,\n",
    "    mixed_effect_mult_global,\n",
    "    mixed_effect_mult_hier,\n",
    "    discount_mult_global,\n",
    "    discount_mult_hier,\n",
    "    discount_slope_global,\n",
    "    discount_slope_hier,\n",
    "    roi_mults_global,\n",
    "    roi_mults_hier,\n",
    "    nr_to_vol_slope,\n",
    "    nr_to_vol_intercept,\n",
    "    time_index_var,\n",
    "    mixed_effect_var,\n",
    "    initial_discount_var,\n",
    "    y_mask_var,\n",
    "    shifted_nr_var\n",
    ")\n",
    "\n",
    "slice_y_inital_pred = tf.slice(y_inital_pred, begin=[0,0], size=[-1, 151])\n",
    "slice_y_initial_vol_pred = tf.slice(y_initial_vol_pred, begin=[0,0], size=[-1, 151])\n",
    "\n",
    "\n",
    "y_opt_pred, y_opt_vol_pred = model(\n",
    "    baseline_intercept,\n",
    "    baseline_slope1_global,\n",
    "    baseline_slope1_hier,\n",
    "    baseline_slope2_global,\n",
    "    baseline_slope2_hier,\n",
    "    mixed_effect_mult_global,\n",
    "    mixed_effect_mult_hier,\n",
    "    discount_mult_global,\n",
    "    discount_mult_hier,\n",
    "    discount_slope_global,\n",
    "    discount_slope_hier,\n",
    "    roi_mults_global,\n",
    "    roi_mults_hier,\n",
    "    nr_to_vol_slope,\n",
    "    nr_to_vol_intercept,\n",
    "    time_index_var,\n",
    "    mixed_effect_var,\n",
    "    discounts_var,\n",
    "    y_mask_var,\n",
    "    shifted_nr_var\n",
    ")\n",
    "\n",
    "slice_y_opt_pred = tf.slice(y_opt_pred, begin=[0,0], size=[-1, 151])\n",
    "slice_y_opt_vol_pred = tf.slice(y_opt_vol_pred, begin=[0,0], size=[-1, 151])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_var_brand = _tensor_gather(sliced_discount_var, final_encodings, \"brand\")\n",
    "discount_var_pack = _tensor_gather(sliced_discount_var, final_encodings, \"pack\")\n",
    "discount_var_segment = _tensor_gather(sliced_discount_var, final_encodings, \"segment\")\n",
    "\n",
    "brand_constraint_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(brand_constraint_tensor - discount_var_brand)))\n",
    "pack_constraint_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(pack_constraint_tensor - discount_var_pack)))\n",
    "segment_constraint_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(segment_constraint_tensor - discount_var_segment)))\n",
    "\n",
    "volume_variation_constraint_temp = pd.DataFrame(index=target_sku_list, columns= [\"minimum_volume_variation\", \"maximum_volume_variation\"]).fillna(constraints_dict[\"volume_variation\"].set_index(\"sku\")[[\"minimum_volume_variation\", \"maximum_volume_variation\"]])\n",
    "volume_variation_constraint_mask = volume_variation_constraint_temp.notna().any(axis=1).to_numpy()\n",
    "\n",
    "vol_var_cons_ref_tensor = tf.boolean_mask(tf.stack([y_vol[-1,:151], y_opt_vol_pred[0,:151]], axis=0), volume_variation_constraint_mask, axis=1)\n",
    "vol_var_cons_vol_tensor = tf.boolean_mask(tf.slice(y_opt_vol_pred, begin=[0,0], size=[-1, 151]), volume_variation_constraint_mask, axis=1)\n",
    "vol_var_cons_val = tf.constant(np.expand_dims(volume_variation_constraint_temp.dropna().values, axis=0), dtype=tf.float64)\n",
    "\n",
    "vol_var_cons_lower = tf.multiply(vol_var_cons_ref_tensor, 1 + vol_var_cons_val[:,:,0])\n",
    "vol_var_cons_upper = tf.multiply(vol_var_cons_ref_tensor, 1 + vol_var_cons_val[:,:,1])\n",
    "\n",
    "\n",
    "volume_sku_constraint_upper_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(vol_var_cons_vol_tensor - vol_var_cons_upper)))\n",
    "volume_sku_constraint_lower_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(vol_var_cons_lower - vol_var_cons_vol_tensor)))\n",
    "\n",
    "negative_discount_loss = tf.reduce_sum(tf.math.square(tf.nn.relu(sliced_discount_var)))\n",
    "\n",
    "nr_increase = tf.reduce_sum(slice_y_opt_pred - slice_y_inital_pred)\n",
    "investment = -tf.reduce_sum(discounts_var)\n",
    "roi = tf.divide(tf.reduce_sum(slice_y_opt_pred - slice_y_inital_pred), -tf.reduce_sum(sliced_discount_var))\n",
    "\n",
    "loss_roi = (\n",
    "    -1e2*roi\n",
    "    +1e5*brand_constraint_loss\n",
    "    +1e5*pack_constraint_loss\n",
    "    +1e5*segment_constraint_loss\n",
    "    +1e5*volume_sku_constraint_upper_loss\n",
    "    +1e5*volume_sku_constraint_lower_loss\n",
    "    +1e5*negative_discount_loss\n",
    "    -1e1*nr_increase\n",
    "    # +0.1*investment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def splitter_func(tensor_to_split):\n",
    "    return [*tf.split(tf.slice(tensor_to_split, begin=[0,0], size=[34, -1]),2), tf.slice(tensor_to_split, begin=[34,0], size=[-1,-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split = splitter_func(y)\n",
    "y_pred_split = splitter_func(y_pred)\n",
    "\n",
    "y_vol_split = splitter_func(y_vol)\n",
    "y_vol_pred_split = splitter_func(y_vol_pred)\n",
    "\n",
    "\n",
    "# loss\n",
    "total_wape = tf.math.reduce_mean([wape(y_split[i], y_pred_split[i]) for i in range(0,val_splitter)]) + wape(tf.slice(y, begin=[0,0], size=[-1, 151]), tf.slice(y_pred, begin=[0,0], size=[-1, 151]))\n",
    "special_wape = wape(tf.slice(y, begin=[0,0], size=[-1, 151]), tf.slice(y_pred, begin=[0,0], size=[-1, 151]))\n",
    "total_mse = mse(y, y_pred)\n",
    "actual_wape = wape(y, y_pred)\n",
    "\n",
    "total_wape_vol = tf.math.reduce_mean([wape(y_vol_split[i], y_vol_pred_split[i]) for i in range(0,val_splitter)]) + wape(tf.slice(y_vol, begin=[0,0], size=[-1, 151]), tf.slice(y_vol_pred, begin=[0,0], size=[-1, 151]))\n",
    "total_mse_vol = mse(y_vol, y_vol_pred)\n",
    "actual_wape_vol = wape(y_vol, y_vol_pred)\n",
    "\n",
    "\n",
    "reg1 = sum([tf.reduce_sum(tf.square(i)) for i in hier_var_list])\n",
    "reg2 = sum([tf.reduce_sum(tf.square(i)) for i in global_var_list])\n",
    "\n",
    "loss = (\n",
    "    1e3*total_wape_vol\n",
    "    +1e1*total_mse_vol\n",
    "    +1e3*total_wape\n",
    "    +1e3*special_wape\n",
    "    +1e1*total_mse\n",
    "    +1e1*reg2\n",
    "    +1e1*reg1\n",
    "    +1e3*volume_sku_constraint_upper_loss\n",
    "    +1e3*volume_sku_constraint_lower_loss\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = 53\n",
    "feed_dict1 = {\n",
    "    discounts : discount_data[:splitter],\n",
    "    mixed_effect: macro_data[:splitter],\n",
    "    y_vol : volume_data[:splitter],\n",
    "    y : nr_data[:splitter],\n",
    "    shifted_nr : nr_shifted[:splitter],\n",
    "    y_mask : nr_data_mask[:splitter],\n",
    "    time_index : time_index_array[:splitter],\n",
    "    val_splitter_ : 5,\n",
    "    initial_discount_var : discount_data[-2:],\n",
    "    mixed_effect_var : macro_data[-2:],\n",
    "    time_index_var : time_index_array[-2:],\n",
    "    y_mask_var : nr_data_mask[-2:],\n",
    "    shifted_nr_var : nr_shifted[-2:]\n",
    "}\n",
    "\n",
    "\n",
    "# feed_dict1 = {\n",
    "#     discounts : discount_data[:splitter],\n",
    "#     mixed_effect: macro_data[:splitter],\n",
    "#     y_vol : volume_data[:splitter],\n",
    "#     y : nr_data[:splitter],\n",
    "#     # shifted_nr : nr_shifted[:splitter],\n",
    "#     y_mask : nr_data_mask[:splitter],\n",
    "#     time_index : time_index_array[:splitter],\n",
    "#     val_splitter_ : 5,\n",
    "#     initial_discount_var : discount_data[-2:],\n",
    "#     mixed_effect_var : macro_data[-2:],\n",
    "#     time_index_var : time_index_array[-2:],\n",
    "#     y_mask_var : nr_data_mask[-2:]\n",
    "# }\n",
    "\n",
    "# feed_dict2 = {\n",
    "#     discounts : discount_data[splitter:-5],\n",
    "#     mixed_effect: macro_data[splitter:-5],\n",
    "#     y_vol : volume_data[splitter:-5],\n",
    "#     y : nr_data[splitter:-5],\n",
    "#     # shifted_nr : nr_shifted[splitter:-5],\n",
    "#     y_mask : nr_data_mask[splitter:-5],\n",
    "#     time_index : time_index_array[splitter:-5],\n",
    "#     val_splitter_ : 5,\n",
    "#     initial_discount_var : discount_data[-2:],\n",
    "#     mixed_effect_var : macro_data[-2:],\n",
    "#     time_index_var : time_index_array[-2:],\n",
    "#     y_mask_var : nr_data_mask[-2:]\n",
    "# }\n",
    "\n",
    "# feed_dict3 = {\n",
    "#     discounts : discount_data[-2:],\n",
    "#     mixed_effect: macro_data[-2:],\n",
    "#     y_vol : volume_data[-2:],\n",
    "#     y : nr_data[-2:],\n",
    "#     # shifted_nr : nr_shifted[-2:],\n",
    "#     y_mask : nr_data_mask[-2:],\n",
    "#     time_index : time_index_array[-2:],\n",
    "#     val_splitter_ : 5\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# optimizer\n",
    "lr = lambda x : 1 / np.power(x/5 + 10, 1/2)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=lr(epoch))#, beta1=0.1, beta2=0.1)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31622776601683794,\n",
       " 0.31311214554257477,\n",
       " 0.2886751345948129,\n",
       " 0.18257418583505536,\n",
       " 0.06900655593423542,\n",
       " 0.022304986837273527,\n",
       " 0.015791661046371634]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lr(i) for i in [0, 1, 10, 100, 1000, 10000, 20000]]#, 50000, 80000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# optimizer\n",
    "lr2 = lambda x : 0.5 / np.power(x/5 + 10, 1/2.5)\n",
    "optimizer_roi = tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)#, beta1=0.1, beta2=0.1)\n",
    "train_roi = optimizer_roi.minimize(loss_roi, var_list=[discounts_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19905358527674863,\n",
       " 0.19748309985118997,\n",
       " 0.18505358624357665,\n",
       " 0.1282689390121013,\n",
       " 0.05889552350375349,\n",
       " 0.023861161564834817,\n",
       " 0.018101403746176976,\n",
       " 0.01255441189851496,\n",
       " 0.010404314501437794]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lr2(i) for i in [0, 1, 10, 100, 1000, 10000, 20000, 50000, 80000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init, feed_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/60000, Loss: 760848.9092, WAPE: 0.2081, WAPE_TEST: 0.2069, WAPE_VOL: 0.2017, WAPE_VOL_TEST: 0.1971, reg1: 2329.8390, reg2: 699.7108, VOL_CONS_UPPER_LOSS: 4.3630, VOL_CONS_LOWER_LOSS: 1.4195\n",
      "Epoch 500/60000, Loss: 593104.3897, WAPE: 0.1947, WAPE_TEST: 0.1929, WAPE_VOL: 0.1732, WAPE_VOL_TEST: 0.1704, reg1: 3030.8252, reg2: 613.1645, VOL_CONS_UPPER_LOSS: 0.0912, VOL_CONS_LOWER_LOSS: 0.8397\n",
      "Epoch 750/60000, Loss: 502945.4891, WAPE: 0.1802, WAPE_TEST: 0.1801, WAPE_VOL: 0.1575, WAPE_VOL_TEST: 0.1574, reg1: 2845.4890, reg2: 557.7905, VOL_CONS_UPPER_LOSS: 0.5918, VOL_CONS_LOWER_LOSS: 0.0689\n",
      "Epoch 1000/60000, Loss: 495661.9720, WAPE: 0.1770, WAPE_TEST: 0.1770, WAPE_VOL: 0.1552, WAPE_VOL_TEST: 0.1551, reg1: 2829.7340, reg2: 576.1805, VOL_CONS_UPPER_LOSS: 0.8935, VOL_CONS_LOWER_LOSS: 0.0539\n",
      "Epoch 1250/60000, Loss: 535924.9006, WAPE: 0.1834, WAPE_TEST: 0.1829, WAPE_VOL: 0.1673, WAPE_VOL_TEST: 0.1660, reg1: 2786.5664, reg2: 619.3729, VOL_CONS_UPPER_LOSS: 0.0333, VOL_CONS_LOWER_LOSS: 0.3635\n",
      "Epoch 1500/60000, Loss: 493955.8615, WAPE: 0.1748, WAPE_TEST: 0.1754, WAPE_VOL: 0.1547, WAPE_VOL_TEST: 0.1546, reg1: 2656.3080, reg2: 659.3639, VOL_CONS_UPPER_LOSS: 0.0193, VOL_CONS_LOWER_LOSS: 0.1650\n",
      "Epoch 1750/60000, Loss: 488234.0605, WAPE: 0.1749, WAPE_TEST: 0.1749, WAPE_VOL: 0.1537, WAPE_VOL_TEST: 0.1533, reg1: 2615.1595, reg2: 715.5984, VOL_CONS_UPPER_LOSS: 0.4061, VOL_CONS_LOWER_LOSS: 0.0826\n",
      "Epoch 2000/60000, Loss: 487485.8413, WAPE: 0.1758, WAPE_TEST: 0.1743, WAPE_VOL: 0.1545, WAPE_VOL_TEST: 0.1534, reg1: 2641.2703, reg2: 736.6677, VOL_CONS_UPPER_LOSS: 0.1495, VOL_CONS_LOWER_LOSS: 0.0748\n",
      "Epoch 2250/60000, Loss: 493307.5503, WAPE: 0.1782, WAPE_TEST: 0.1778, WAPE_VOL: 0.1598, WAPE_VOL_TEST: 0.1599, reg1: 2679.1576, reg2: 850.9612, VOL_CONS_UPPER_LOSS: 6.0422, VOL_CONS_LOWER_LOSS: 0.4008\n",
      "Epoch 2500/60000, Loss: 485637.4192, WAPE: 0.1753, WAPE_TEST: 0.1757, WAPE_VOL: 0.1546, WAPE_VOL_TEST: 0.1547, reg1: 2637.7340, reg2: 825.8744, VOL_CONS_UPPER_LOSS: 0.2686, VOL_CONS_LOWER_LOSS: 0.2187\n",
      "Epoch 2750/60000, Loss: 522401.6992, WAPE: 0.1785, WAPE_TEST: 0.1744, WAPE_VOL: 0.1649, WAPE_VOL_TEST: 0.1637, reg1: 2636.6902, reg2: 825.8010, VOL_CONS_UPPER_LOSS: 3.1765, VOL_CONS_LOWER_LOSS: 0.0287\n",
      "Epoch 3000/60000, Loss: 518866.1007, WAPE: 0.1800, WAPE_TEST: 0.1798, WAPE_VOL: 0.1642, WAPE_VOL_TEST: 0.1637, reg1: 2768.2059, reg2: 1063.3001, VOL_CONS_UPPER_LOSS: 0.0053, VOL_CONS_LOWER_LOSS: 1.9826\n",
      "Epoch 3250/60000, Loss: 511076.2106, WAPE: 0.1797, WAPE_TEST: 0.1787, WAPE_VOL: 0.1617, WAPE_VOL_TEST: 0.1601, reg1: 2680.8118, reg2: 1023.5827, VOL_CONS_UPPER_LOSS: 0.6466, VOL_CONS_LOWER_LOSS: 1.5659\n",
      "Epoch 3500/60000, Loss: 522808.6047, WAPE: 0.1787, WAPE_TEST: 0.1807, WAPE_VOL: 0.1624, WAPE_VOL_TEST: 0.1653, reg1: 2627.5431, reg2: 999.8848, VOL_CONS_UPPER_LOSS: 0.0058, VOL_CONS_LOWER_LOSS: 1.6668\n",
      "Epoch 3750/60000, Loss: 520362.1014, WAPE: 0.1801, WAPE_TEST: 0.1810, WAPE_VOL: 0.1653, WAPE_VOL_TEST: 0.1674, reg1: 2688.7198, reg2: 907.4274, VOL_CONS_UPPER_LOSS: 0.0092, VOL_CONS_LOWER_LOSS: 0.4303\n",
      "Epoch 4000/60000, Loss: 483307.3643, WAPE: 0.1723, WAPE_TEST: 0.1738, WAPE_VOL: 0.1560, WAPE_VOL_TEST: 0.1562, reg1: 2606.1675, reg2: 903.3264, VOL_CONS_UPPER_LOSS: 0.1178, VOL_CONS_LOWER_LOSS: 0.1402\n",
      "Epoch 4250/60000, Loss: 577409.8674, WAPE: 0.1820, WAPE_TEST: 0.1790, WAPE_VOL: 0.1651, WAPE_VOL_TEST: 0.1633, reg1: 2644.6096, reg2: 904.2381, VOL_CONS_UPPER_LOSS: 0.0091, VOL_CONS_LOWER_LOSS: 0.0342\n",
      "Epoch 4500/60000, Loss: 484717.8314, WAPE: 0.1734, WAPE_TEST: 0.1749, WAPE_VOL: 0.1564, WAPE_VOL_TEST: 0.1571, reg1: 2600.4696, reg2: 918.2105, VOL_CONS_UPPER_LOSS: 1.8731, VOL_CONS_LOWER_LOSS: 0.2448\n",
      "Epoch 4750/60000, Loss: 502506.0120, WAPE: 0.1746, WAPE_TEST: 0.1778, WAPE_VOL: 0.1611, WAPE_VOL_TEST: 0.1611, reg1: 2592.7558, reg2: 887.8589, VOL_CONS_UPPER_LOSS: 0.0064, VOL_CONS_LOWER_LOSS: 0.1834\n",
      "Epoch 5000/60000, Loss: 482148.1393, WAPE: 0.1737, WAPE_TEST: 0.1731, WAPE_VOL: 0.1558, WAPE_VOL_TEST: 0.1553, reg1: 2546.8999, reg2: 939.8419, VOL_CONS_UPPER_LOSS: 0.7333, VOL_CONS_LOWER_LOSS: 0.0652\n",
      "Epoch 5250/60000, Loss: 524401.5966, WAPE: 0.1770, WAPE_TEST: 0.1742, WAPE_VOL: 0.1637, WAPE_VOL_TEST: 0.1637, reg1: 2515.6015, reg2: 976.8073, VOL_CONS_UPPER_LOSS: 0.4497, VOL_CONS_LOWER_LOSS: 0.0163\n",
      "Epoch 5500/60000, Loss: 481438.2310, WAPE: 0.1729, WAPE_TEST: 0.1740, WAPE_VOL: 0.1554, WAPE_VOL_TEST: 0.1558, reg1: 2512.9293, reg2: 946.1498, VOL_CONS_UPPER_LOSS: 0.8443, VOL_CONS_LOWER_LOSS: 0.1643\n",
      "Epoch 5750/60000, Loss: 490160.8202, WAPE: 0.1728, WAPE_TEST: 0.1753, WAPE_VOL: 0.1587, WAPE_VOL_TEST: 0.1603, reg1: 2503.4635, reg2: 909.9650, VOL_CONS_UPPER_LOSS: 6.3632, VOL_CONS_LOWER_LOSS: 0.2533\n",
      "Epoch 6000/60000, Loss: 574458.5222, WAPE: 0.1828, WAPE_TEST: 0.1789, WAPE_VOL: 0.1781, WAPE_VOL_TEST: 0.1776, reg1: 2520.0072, reg2: 949.4506, VOL_CONS_UPPER_LOSS: 3.9184, VOL_CONS_LOWER_LOSS: 0.2639\n",
      "Epoch 6250/60000, Loss: 482190.1971, WAPE: 0.1740, WAPE_TEST: 0.1734, WAPE_VOL: 0.1568, WAPE_VOL_TEST: 0.1552, reg1: 2506.8860, reg2: 953.5639, VOL_CONS_UPPER_LOSS: 0.0454, VOL_CONS_LOWER_LOSS: 0.0438\n",
      "Epoch 6500/60000, Loss: 489208.6283, WAPE: 0.1740, WAPE_TEST: 0.1750, WAPE_VOL: 0.1563, WAPE_VOL_TEST: 0.1561, reg1: 2486.6062, reg2: 959.5227, VOL_CONS_UPPER_LOSS: 0.0388, VOL_CONS_LOWER_LOSS: 0.1048\n",
      "Epoch 6750/60000, Loss: 485217.2302, WAPE: 0.1750, WAPE_TEST: 0.1735, WAPE_VOL: 0.1567, WAPE_VOL_TEST: 0.1560, reg1: 2489.1725, reg2: 948.0185, VOL_CONS_UPPER_LOSS: 0.0921, VOL_CONS_LOWER_LOSS: 0.0603\n",
      "Epoch 7000/60000, Loss: 580838.9393, WAPE: 0.1790, WAPE_TEST: 0.1781, WAPE_VOL: 0.1721, WAPE_VOL_TEST: 0.1698, reg1: 2561.5341, reg2: 1053.3676, VOL_CONS_UPPER_LOSS: 3.6804, VOL_CONS_LOWER_LOSS: 0.1865\n",
      "Epoch 7250/60000, Loss: 487296.8259, WAPE: 0.1743, WAPE_TEST: 0.1752, WAPE_VOL: 0.1565, WAPE_VOL_TEST: 0.1571, reg1: 2481.0132, reg2: 971.7103, VOL_CONS_UPPER_LOSS: 0.0245, VOL_CONS_LOWER_LOSS: 0.3087\n",
      "Epoch 7500/60000, Loss: 502568.3744, WAPE: 0.1744, WAPE_TEST: 0.1800, WAPE_VOL: 0.1639, WAPE_VOL_TEST: 0.1702, reg1: 2497.9222, reg2: 956.7195, VOL_CONS_UPPER_LOSS: 0.0134, VOL_CONS_LOWER_LOSS: 0.0606\n",
      "Epoch 7750/60000, Loss: 505119.6199, WAPE: 0.1773, WAPE_TEST: 0.1784, WAPE_VOL: 0.1682, WAPE_VOL_TEST: 0.1644, reg1: 2501.5158, reg2: 975.9427, VOL_CONS_UPPER_LOSS: 0.0092, VOL_CONS_LOWER_LOSS: 0.6688\n",
      "Epoch 8000/60000, Loss: 562851.8324, WAPE: 0.1837, WAPE_TEST: 0.1796, WAPE_VOL: 0.1729, WAPE_VOL_TEST: 0.1718, reg1: 2550.6050, reg2: 1004.9191, VOL_CONS_UPPER_LOSS: 1.0954, VOL_CONS_LOWER_LOSS: 0.1504\n",
      "Epoch 8250/60000, Loss: 482535.6964, WAPE: 0.1732, WAPE_TEST: 0.1749, WAPE_VOL: 0.1559, WAPE_VOL_TEST: 0.1569, reg1: 2501.3377, reg2: 953.5690, VOL_CONS_UPPER_LOSS: 0.2889, VOL_CONS_LOWER_LOSS: 0.0593\n",
      "Epoch 8500/60000, Loss: 526856.0150, WAPE: 0.1735, WAPE_TEST: 0.1777, WAPE_VOL: 0.1634, WAPE_VOL_TEST: 0.1628, reg1: 2490.0314, reg2: 939.8387, VOL_CONS_UPPER_LOSS: 21.1117, VOL_CONS_LOWER_LOSS: 0.2833\n",
      "Epoch 8750/60000, Loss: 587156.2385, WAPE: 0.1817, WAPE_TEST: 0.1832, WAPE_VOL: 0.1893, WAPE_VOL_TEST: 0.1855, reg1: 2504.4787, reg2: 985.1753, VOL_CONS_UPPER_LOSS: 2.1832, VOL_CONS_LOWER_LOSS: 2.4353\n",
      "Epoch 9000/60000, Loss: 486085.1022, WAPE: 0.1758, WAPE_TEST: 0.1760, WAPE_VOL: 0.1589, WAPE_VOL_TEST: 0.1589, reg1: 2493.2410, reg2: 963.7112, VOL_CONS_UPPER_LOSS: 0.0092, VOL_CONS_LOWER_LOSS: 0.0347\n",
      "Epoch 9250/60000, Loss: 608300.5048, WAPE: 0.1802, WAPE_TEST: 0.1795, WAPE_VOL: 0.1702, WAPE_VOL_TEST: 0.1638, reg1: 2527.9980, reg2: 1128.4449, VOL_CONS_UPPER_LOSS: 59.4350, VOL_CONS_LOWER_LOSS: 0.1001\n",
      "Epoch 9500/60000, Loss: 483058.8182, WAPE: 0.1738, WAPE_TEST: 0.1751, WAPE_VOL: 0.1569, WAPE_VOL_TEST: 0.1569, reg1: 2475.5007, reg2: 989.3096, VOL_CONS_UPPER_LOSS: 1.0062, VOL_CONS_LOWER_LOSS: 0.2559\n",
      "Epoch 9750/60000, Loss: 479748.4555, WAPE: 0.1720, WAPE_TEST: 0.1730, WAPE_VOL: 0.1563, WAPE_VOL_TEST: 0.1562, reg1: 2452.3669, reg2: 932.0343, VOL_CONS_UPPER_LOSS: 1.0396, VOL_CONS_LOWER_LOSS: 0.1815\n",
      "Epoch 10000/60000, Loss: 483607.6736, WAPE: 0.1718, WAPE_TEST: 0.1755, WAPE_VOL: 0.1572, WAPE_VOL_TEST: 0.1584, reg1: 2503.5693, reg2: 981.6181, VOL_CONS_UPPER_LOSS: 0.3508, VOL_CONS_LOWER_LOSS: 0.2096\n",
      "Epoch 10250/60000, Loss: 483130.6463, WAPE: 0.1736, WAPE_TEST: 0.1718, WAPE_VOL: 0.1577, WAPE_VOL_TEST: 0.1569, reg1: 2476.2037, reg2: 943.4730, VOL_CONS_UPPER_LOSS: 0.0971, VOL_CONS_LOWER_LOSS: 0.1009\n",
      "Epoch 10500/60000, Loss: 497531.6111, WAPE: 0.1719, WAPE_TEST: 0.1786, WAPE_VOL: 0.1585, WAPE_VOL_TEST: 0.1631, reg1: 2479.1345, reg2: 945.1080, VOL_CONS_UPPER_LOSS: 12.5446, VOL_CONS_LOWER_LOSS: 0.3116\n",
      "Epoch 10750/60000, Loss: 532791.4519, WAPE: 0.1805, WAPE_TEST: 0.1805, WAPE_VOL: 0.1640, WAPE_VOL_TEST: 0.1620, reg1: 2472.5805, reg2: 1032.5885, VOL_CONS_UPPER_LOSS: 0.0080, VOL_CONS_LOWER_LOSS: 0.3212\n",
      "Epoch 11000/60000, Loss: 478137.4643, WAPE: 0.1743, WAPE_TEST: 0.1720, WAPE_VOL: 0.1563, WAPE_VOL_TEST: 0.1552, reg1: 2477.9078, reg2: 962.2084, VOL_CONS_UPPER_LOSS: 0.7060, VOL_CONS_LOWER_LOSS: 0.0401\n",
      "Epoch 11250/60000, Loss: 484403.8019, WAPE: 0.1726, WAPE_TEST: 0.1752, WAPE_VOL: 0.1564, WAPE_VOL_TEST: 0.1587, reg1: 2487.9468, reg2: 938.0556, VOL_CONS_UPPER_LOSS: 1.8056, VOL_CONS_LOWER_LOSS: 0.2288\n",
      "Epoch 11500/60000, Loss: 1305002.7809, WAPE: 0.2807, WAPE_TEST: 0.2904, WAPE_VOL: 0.2817, WAPE_VOL_TEST: 0.2690, reg1: 4664.5468, reg2: 2217.5674, VOL_CONS_UPPER_LOSS: 29.5056, VOL_CONS_LOWER_LOSS: 0.7388\n",
      "Epoch 11750/60000, Loss: 847520.5050, WAPE: 0.2156, WAPE_TEST: 0.2154, WAPE_VOL: 0.1827, WAPE_VOL_TEST: 0.1819, reg1: 2810.3511, reg2: 2030.4089, VOL_CONS_UPPER_LOSS: 0.7252, VOL_CONS_LOWER_LOSS: 1.5162\n",
      "Epoch 12000/60000, Loss: 840389.6022, WAPE: 0.2138, WAPE_TEST: 0.2133, WAPE_VOL: 0.1804, WAPE_VOL_TEST: 0.1794, reg1: 2509.0119, reg2: 2174.9185, VOL_CONS_UPPER_LOSS: 0.5615, VOL_CONS_LOWER_LOSS: 1.5211\n",
      "Epoch 12250/60000, Loss: 1315640.5378, WAPE: 0.2553, WAPE_TEST: 0.2537, WAPE_VOL: 0.2269, WAPE_VOL_TEST: 0.2406, reg1: 2562.2733, reg2: 2183.6283, VOL_CONS_UPPER_LOSS: 0.7459, VOL_CONS_LOWER_LOSS: 244.5755\n",
      "Epoch 12500/60000, Loss: 809554.3339, WAPE: 0.2151, WAPE_TEST: 0.2145, WAPE_VOL: 0.1820, WAPE_VOL_TEST: 0.1814, reg1: 2661.6626, reg2: 1783.3261, VOL_CONS_UPPER_LOSS: 0.9035, VOL_CONS_LOWER_LOSS: 1.3928\n",
      "Epoch 12750/60000, Loss: 778214.1283, WAPE: 0.2132, WAPE_TEST: 0.2124, WAPE_VOL: 0.1808, WAPE_VOL_TEST: 0.1793, reg1: 2537.1935, reg2: 1622.9066, VOL_CONS_UPPER_LOSS: 0.1413, VOL_CONS_LOWER_LOSS: 1.6452\n",
      "Epoch 13000/60000, Loss: 580338.9730, WAPE: 0.1880, WAPE_TEST: 0.1884, WAPE_VOL: 0.1784, WAPE_VOL_TEST: 0.1794, reg1: 2499.2004, reg2: 1255.9356, VOL_CONS_UPPER_LOSS: 0.7964, VOL_CONS_LOWER_LOSS: 7.0166\n",
      "Epoch 13250/60000, Loss: 520446.4883, WAPE: 0.1828, WAPE_TEST: 0.1827, WAPE_VOL: 0.1747, WAPE_VOL_TEST: 0.1739, reg1: 2485.9508, reg2: 1162.4374, VOL_CONS_UPPER_LOSS: 1.9412, VOL_CONS_LOWER_LOSS: 2.1733\n",
      "Epoch 13500/60000, Loss: 576183.1643, WAPE: 0.1862, WAPE_TEST: 0.1886, WAPE_VOL: 0.1821, WAPE_VOL_TEST: 0.1797, reg1: 2467.6690, reg2: 1118.6275, VOL_CONS_UPPER_LOSS: 0.1091, VOL_CONS_LOWER_LOSS: 12.9383\n",
      "Epoch 13750/60000, Loss: 524493.5620, WAPE: 0.1820, WAPE_TEST: 0.1824, WAPE_VOL: 0.1751, WAPE_VOL_TEST: 0.1750, reg1: 2465.0648, reg2: 1214.7749, VOL_CONS_UPPER_LOSS: 0.0507, VOL_CONS_LOWER_LOSS: 2.4329\n",
      "Epoch 14000/60000, Loss: 517501.0935, WAPE: 0.1820, WAPE_TEST: 0.1822, WAPE_VOL: 0.1733, WAPE_VOL_TEST: 0.1731, reg1: 2461.6906, reg2: 1102.1919, VOL_CONS_UPPER_LOSS: 1.2655, VOL_CONS_LOWER_LOSS: 2.1074\n",
      "Epoch 14250/60000, Loss: 532823.1182, WAPE: 0.1847, WAPE_TEST: 0.1834, WAPE_VOL: 0.1747, WAPE_VOL_TEST: 0.1737, reg1: 2463.1683, reg2: 1067.8823, VOL_CONS_UPPER_LOSS: 0.5256, VOL_CONS_LOWER_LOSS: 2.1607\n",
      "Epoch 14500/60000, Loss: 656740.3506, WAPE: 0.2012, WAPE_TEST: 0.2066, WAPE_VOL: 0.2106, WAPE_VOL_TEST: 0.2098, reg1: 2445.5797, reg2: 1061.2200, VOL_CONS_UPPER_LOSS: 0.0110, VOL_CONS_LOWER_LOSS: 6.0221\n",
      "Epoch 14750/60000, Loss: 598632.4410, WAPE: 0.1884, WAPE_TEST: 0.2006, WAPE_VOL: 0.1928, WAPE_VOL_TEST: 0.1980, reg1: 2457.5138, reg2: 1086.4670, VOL_CONS_UPPER_LOSS: 0.0054, VOL_CONS_LOWER_LOSS: 3.3152\n",
      "Epoch 15000/60000, Loss: 520911.2830, WAPE: 0.1838, WAPE_TEST: 0.1835, WAPE_VOL: 0.1733, WAPE_VOL_TEST: 0.1748, reg1: 2439.3108, reg2: 1066.9500, VOL_CONS_UPPER_LOSS: 0.1835, VOL_CONS_LOWER_LOSS: 1.9662\n",
      "Epoch 15250/60000, Loss: 541312.1458, WAPE: 0.1828, WAPE_TEST: 0.1836, WAPE_VOL: 0.1757, WAPE_VOL_TEST: 0.1754, reg1: 2473.5411, reg2: 1046.4486, VOL_CONS_UPPER_LOSS: 11.4620, VOL_CONS_LOWER_LOSS: 2.0201\n",
      "Epoch 15500/60000, Loss: 575394.5492, WAPE: 0.1885, WAPE_TEST: 0.1890, WAPE_VOL: 0.1889, WAPE_VOL_TEST: 0.1886, reg1: 2637.8315, reg2: 1083.1985, VOL_CONS_UPPER_LOSS: 12.3627, VOL_CONS_LOWER_LOSS: 19.7425\n",
      "Epoch 15750/60000, Loss: 520381.6143, WAPE: 0.1852, WAPE_TEST: 0.1837, WAPE_VOL: 0.1776, WAPE_VOL_TEST: 0.1762, reg1: 2617.1399, reg2: 1051.7546, VOL_CONS_UPPER_LOSS: 0.4893, VOL_CONS_LOWER_LOSS: 2.3490\n",
      "Epoch 16000/60000, Loss: 511276.0922, WAPE: 0.1821, WAPE_TEST: 0.1824, WAPE_VOL: 0.1690, WAPE_VOL_TEST: 0.1690, reg1: 2553.4501, reg2: 982.9915, VOL_CONS_UPPER_LOSS: 0.2541, VOL_CONS_LOWER_LOSS: 1.9443\n",
      "Epoch 16250/60000, Loss: 512473.7143, WAPE: 0.1818, WAPE_TEST: 0.1825, WAPE_VOL: 0.1701, WAPE_VOL_TEST: 0.1694, reg1: 2558.0175, reg2: 1005.0374, VOL_CONS_UPPER_LOSS: 0.6728, VOL_CONS_LOWER_LOSS: 1.9497\n",
      "Epoch 16500/60000, Loss: 552815.9067, WAPE: 0.1843, WAPE_TEST: 0.1842, WAPE_VOL: 0.1896, WAPE_VOL_TEST: 0.1866, reg1: 2854.0339, reg2: 1034.3012, VOL_CONS_UPPER_LOSS: 0.1757, VOL_CONS_LOWER_LOSS: 2.1436\n",
      "Epoch 16750/60000, Loss: 533692.6614, WAPE: 0.1820, WAPE_TEST: 0.1824, WAPE_VOL: 0.1726, WAPE_VOL_TEST: 0.1716, reg1: 2672.9923, reg2: 1024.2590, VOL_CONS_UPPER_LOSS: 9.8393, VOL_CONS_LOWER_LOSS: 2.1027\n",
      "Epoch 17000/60000, Loss: 511450.8116, WAPE: 0.1817, WAPE_TEST: 0.1818, WAPE_VOL: 0.1693, WAPE_VOL_TEST: 0.1689, reg1: 2614.1033, reg2: 999.1807, VOL_CONS_UPPER_LOSS: 0.6014, VOL_CONS_LOWER_LOSS: 1.9758\n",
      "Epoch 17250/60000, Loss: 525830.3606, WAPE: 0.1833, WAPE_TEST: 0.1845, WAPE_VOL: 0.1743, WAPE_VOL_TEST: 0.1721, reg1: 2617.5700, reg2: 990.1101, VOL_CONS_UPPER_LOSS: 0.5771, VOL_CONS_LOWER_LOSS: 1.8974\n",
      "Epoch 17500/60000, Loss: 513342.0188, WAPE: 0.1812, WAPE_TEST: 0.1807, WAPE_VOL: 0.1704, WAPE_VOL_TEST: 0.1693, reg1: 2669.4061, reg2: 1029.0817, VOL_CONS_UPPER_LOSS: 0.2826, VOL_CONS_LOWER_LOSS: 1.9552\n",
      "Epoch 17750/60000, Loss: 510207.0236, WAPE: 0.1808, WAPE_TEST: 0.1809, WAPE_VOL: 0.1687, WAPE_VOL_TEST: 0.1685, reg1: 2583.0795, reg2: 1038.7411, VOL_CONS_UPPER_LOSS: 0.6669, VOL_CONS_LOWER_LOSS: 1.8787\n",
      "Epoch 18000/60000, Loss: 513815.6526, WAPE: 0.1817, WAPE_TEST: 0.1815, WAPE_VOL: 0.1703, WAPE_VOL_TEST: 0.1700, reg1: 2727.3249, reg2: 984.0460, VOL_CONS_UPPER_LOSS: 0.3325, VOL_CONS_LOWER_LOSS: 1.9731\n",
      "Epoch 18250/60000, Loss: 520351.5256, WAPE: 0.1806, WAPE_TEST: 0.1807, WAPE_VOL: 0.1715, WAPE_VOL_TEST: 0.1702, reg1: 2566.8152, reg2: 1009.0540, VOL_CONS_UPPER_LOSS: 10.7018, VOL_CONS_LOWER_LOSS: 2.0024\n",
      "Epoch 18500/60000, Loss: 541097.6116, WAPE: 0.1871, WAPE_TEST: 0.1870, WAPE_VOL: 0.1776, WAPE_VOL_TEST: 0.1773, reg1: 2679.5034, reg2: 1396.6412, VOL_CONS_UPPER_LOSS: 0.7400, VOL_CONS_LOWER_LOSS: 3.5248\n",
      "Epoch 18750/60000, Loss: 533251.0622, WAPE: 0.1848, WAPE_TEST: 0.1861, WAPE_VOL: 0.1728, WAPE_VOL_TEST: 0.1733, reg1: 2556.5312, reg2: 1224.2352, VOL_CONS_UPPER_LOSS: 0.5979, VOL_CONS_LOWER_LOSS: 3.3346\n",
      "Epoch 19000/60000, Loss: 504566.5061, WAPE: 0.1811, WAPE_TEST: 0.1797, WAPE_VOL: 0.1659, WAPE_VOL_TEST: 0.1646, reg1: 2574.7280, reg2: 985.9268, VOL_CONS_UPPER_LOSS: 0.7106, VOL_CONS_LOWER_LOSS: 1.3365\n",
      "Epoch 19250/60000, Loss: 503131.4963, WAPE: 0.1797, WAPE_TEST: 0.1798, WAPE_VOL: 0.1646, WAPE_VOL_TEST: 0.1650, reg1: 2523.9226, reg2: 957.6265, VOL_CONS_UPPER_LOSS: 0.0749, VOL_CONS_LOWER_LOSS: 1.5230\n",
      "Epoch 19500/60000, Loss: 645106.6103, WAPE: 0.1903, WAPE_TEST: 0.1862, WAPE_VOL: 0.1753, WAPE_VOL_TEST: 0.1723, reg1: 2497.4525, reg2: 968.1600, VOL_CONS_UPPER_LOSS: 0.3858, VOL_CONS_LOWER_LOSS: 1.4198\n",
      "Epoch 19750/60000, Loss: 638258.0052, WAPE: 0.1940, WAPE_TEST: 0.1941, WAPE_VOL: 0.1899, WAPE_VOL_TEST: 0.1893, reg1: 3257.2705, reg2: 1826.5676, VOL_CONS_UPPER_LOSS: 0.5991, VOL_CONS_LOWER_LOSS: 2.0349\n",
      "Epoch 20000/60000, Loss: 604294.1966, WAPE: 0.1890, WAPE_TEST: 0.1891, WAPE_VOL: 0.1810, WAPE_VOL_TEST: 0.1808, reg1: 2619.9220, reg2: 2040.2446, VOL_CONS_UPPER_LOSS: 0.5891, VOL_CONS_LOWER_LOSS: 2.1507\n",
      "Epoch 20250/60000, Loss: 531937.1358, WAPE: 0.1837, WAPE_TEST: 0.1860, WAPE_VOL: 0.1780, WAPE_VOL_TEST: 0.1796, reg1: 2537.8146, reg2: 1887.9982, VOL_CONS_UPPER_LOSS: 0.6939, VOL_CONS_LOWER_LOSS: 2.5050\n",
      "Epoch 20500/60000, Loss: 525407.2056, WAPE: 0.1836, WAPE_TEST: 0.1828, WAPE_VOL: 0.1791, WAPE_VOL_TEST: 0.1770, reg1: 2526.9736, reg2: 1410.7429, VOL_CONS_UPPER_LOSS: 1.0472, VOL_CONS_LOWER_LOSS: 1.7683\n",
      "Epoch 20750/60000, Loss: 532927.7305, WAPE: 0.1824, WAPE_TEST: 0.1843, WAPE_VOL: 0.1778, WAPE_VOL_TEST: 0.1772, reg1: 2511.0887, reg2: 1222.2295, VOL_CONS_UPPER_LOSS: 11.2443, VOL_CONS_LOWER_LOSS: 2.1970\n",
      "Epoch 21000/60000, Loss: 545551.6871, WAPE: 0.1856, WAPE_TEST: 0.1856, WAPE_VOL: 0.1804, WAPE_VOL_TEST: 0.1796, reg1: 2521.8098, reg2: 1165.1549, VOL_CONS_UPPER_LOSS: 19.1321, VOL_CONS_LOWER_LOSS: 2.1740\n",
      "Epoch 21250/60000, Loss: 542492.5712, WAPE: 0.1850, WAPE_TEST: 0.1849, WAPE_VOL: 0.1800, WAPE_VOL_TEST: 0.1787, reg1: 2495.9636, reg2: 1204.2241, VOL_CONS_UPPER_LOSS: 0.0115, VOL_CONS_LOWER_LOSS: 2.2413\n",
      "Epoch 21500/60000, Loss: 517891.9203, WAPE: 0.1826, WAPE_TEST: 0.1824, WAPE_VOL: 0.1751, WAPE_VOL_TEST: 0.1746, reg1: 2474.3884, reg2: 1116.1142, VOL_CONS_UPPER_LOSS: 0.4160, VOL_CONS_LOWER_LOSS: 1.9311\n",
      "Epoch 21750/60000, Loss: 529975.5271, WAPE: 0.1847, WAPE_TEST: 0.1838, WAPE_VOL: 0.1767, WAPE_VOL_TEST: 0.1777, reg1: 2485.1610, reg2: 1096.4482, VOL_CONS_UPPER_LOSS: 0.0783, VOL_CONS_LOWER_LOSS: 2.0136\n",
      "Epoch 22000/60000, Loss: 579103.8715, WAPE: 0.1880, WAPE_TEST: 0.1911, WAPE_VOL: 0.1887, WAPE_VOL_TEST: 0.1864, reg1: 2471.0229, reg2: 1092.1633, VOL_CONS_UPPER_LOSS: 0.0127, VOL_CONS_LOWER_LOSS: 3.5886\n",
      "Epoch 22250/60000, Loss: 516022.7776, WAPE: 0.1821, WAPE_TEST: 0.1821, WAPE_VOL: 0.1737, WAPE_VOL_TEST: 0.1733, reg1: 2447.2400, reg2: 1105.0630, VOL_CONS_UPPER_LOSS: 0.6360, VOL_CONS_LOWER_LOSS: 1.9408\n",
      "Epoch 22500/60000, Loss: 566307.1559, WAPE: 0.1931, WAPE_TEST: 0.1897, WAPE_VOL: 0.1903, WAPE_VOL_TEST: 0.1909, reg1: 2440.0719, reg2: 1099.5246, VOL_CONS_UPPER_LOSS: 1.5109, VOL_CONS_LOWER_LOSS: 1.8007\n",
      "Epoch 22750/60000, Loss: 523622.4877, WAPE: 0.1825, WAPE_TEST: 0.1838, WAPE_VOL: 0.1729, WAPE_VOL_TEST: 0.1722, reg1: 2439.8770, reg2: 1049.7065, VOL_CONS_UPPER_LOSS: 11.8013, VOL_CONS_LOWER_LOSS: 1.4384\n",
      "Epoch 23000/60000, Loss: 511880.6300, WAPE: 0.1820, WAPE_TEST: 0.1825, WAPE_VOL: 0.1705, WAPE_VOL_TEST: 0.1703, reg1: 2570.8044, reg2: 1027.1404, VOL_CONS_UPPER_LOSS: 2.8305, VOL_CONS_LOWER_LOSS: 1.3821\n",
      "Epoch 23250/60000, Loss: 536472.7355, WAPE: 0.1850, WAPE_TEST: 0.1836, WAPE_VOL: 0.1741, WAPE_VOL_TEST: 0.1728, reg1: 2549.4545, reg2: 989.7152, VOL_CONS_UPPER_LOSS: 18.7632, VOL_CONS_LOWER_LOSS: 1.4729\n",
      "Epoch 23500/60000, Loss: 567773.1068, WAPE: 0.1886, WAPE_TEST: 0.1876, WAPE_VOL: 0.1751, WAPE_VOL_TEST: 0.1741, reg1: 2531.8770, reg2: 997.0666, VOL_CONS_UPPER_LOSS: 0.0641, VOL_CONS_LOWER_LOSS: 2.5272\n",
      "Epoch 23750/60000, Loss: 537379.0393, WAPE: 0.1839, WAPE_TEST: 0.1808, WAPE_VOL: 0.1771, WAPE_VOL_TEST: 0.1754, reg1: 2660.1160, reg2: 1022.3592, VOL_CONS_UPPER_LOSS: 5.8374, VOL_CONS_LOWER_LOSS: 1.4199\n",
      "Epoch 24000/60000, Loss: 548173.0232, WAPE: 0.1847, WAPE_TEST: 0.1850, WAPE_VOL: 0.1838, WAPE_VOL_TEST: 0.1827, reg1: 2590.2321, reg2: 1112.4708, VOL_CONS_UPPER_LOSS: 0.5549, VOL_CONS_LOWER_LOSS: 1.4460\n",
      "Epoch 24250/60000, Loss: 528711.1864, WAPE: 0.1815, WAPE_TEST: 0.1796, WAPE_VOL: 0.1712, WAPE_VOL_TEST: 0.1677, reg1: 2558.4395, reg2: 1028.2090, VOL_CONS_UPPER_LOSS: 0.0621, VOL_CONS_LOWER_LOSS: 1.4672\n",
      "Epoch 24500/60000, Loss: 806168.9490, WAPE: 0.1991, WAPE_TEST: 0.2121, WAPE_VOL: 0.2407, WAPE_VOL_TEST: 0.2631, reg1: 2618.4357, reg2: 1038.1997, VOL_CONS_UPPER_LOSS: 40.5057, VOL_CONS_LOWER_LOSS: 7.0605\n",
      "Epoch 24750/60000, Loss: 514210.9905, WAPE: 0.1810, WAPE_TEST: 0.1810, WAPE_VOL: 0.1711, WAPE_VOL_TEST: 0.1706, reg1: 2525.0034, reg2: 1096.0776, VOL_CONS_UPPER_LOSS: 0.6443, VOL_CONS_LOWER_LOSS: 1.6125\n",
      "Epoch 25000/60000, Loss: 513671.8441, WAPE: 0.1822, WAPE_TEST: 0.1826, WAPE_VOL: 0.1702, WAPE_VOL_TEST: 0.1692, reg1: 2525.8619, reg2: 1004.5344, VOL_CONS_UPPER_LOSS: 0.1409, VOL_CONS_LOWER_LOSS: 1.4238\n",
      "Epoch 25250/60000, Loss: 689051.4863, WAPE: 0.1929, WAPE_TEST: 0.1923, WAPE_VOL: 0.1848, WAPE_VOL_TEST: 0.1796, reg1: 2557.1261, reg2: 1056.0455, VOL_CONS_UPPER_LOSS: 0.0079, VOL_CONS_LOWER_LOSS: 11.7788\n",
      "Epoch 25500/60000, Loss: 500494.8053, WAPE: 0.1788, WAPE_TEST: 0.1786, WAPE_VOL: 0.1638, WAPE_VOL_TEST: 0.1637, reg1: 2517.7204, reg2: 996.4090, VOL_CONS_UPPER_LOSS: 0.7120, VOL_CONS_LOWER_LOSS: 1.4372\n",
      "Epoch 25750/60000, Loss: 573996.2618, WAPE: 0.1797, WAPE_TEST: 0.1846, WAPE_VOL: 0.1748, WAPE_VOL_TEST: 0.1722, reg1: 2600.1762, reg2: 1000.7571, VOL_CONS_UPPER_LOSS: 34.6126, VOL_CONS_LOWER_LOSS: 1.7312\n",
      "Epoch 26000/60000, Loss: 552568.1728, WAPE: 0.1877, WAPE_TEST: 0.1808, WAPE_VOL: 0.1867, WAPE_VOL_TEST: 0.1791, reg1: 2647.0471, reg2: 1051.0478, VOL_CONS_UPPER_LOSS: 22.9701, VOL_CONS_LOWER_LOSS: 1.5400\n",
      "Epoch 26250/60000, Loss: 512463.8821, WAPE: 0.1811, WAPE_TEST: 0.1810, WAPE_VOL: 0.1663, WAPE_VOL_TEST: 0.1654, reg1: 2536.8036, reg2: 999.0418, VOL_CONS_UPPER_LOSS: 0.2470, VOL_CONS_LOWER_LOSS: 1.5558\n",
      "Epoch 26500/60000, Loss: 508915.8874, WAPE: 0.1800, WAPE_TEST: 0.1791, WAPE_VOL: 0.1659, WAPE_VOL_TEST: 0.1640, reg1: 2490.9884, reg2: 1082.0710, VOL_CONS_UPPER_LOSS: 0.2756, VOL_CONS_LOWER_LOSS: 1.3888\n",
      "Epoch 26750/60000, Loss: 500928.6969, WAPE: 0.1779, WAPE_TEST: 0.1796, WAPE_VOL: 0.1638, WAPE_VOL_TEST: 0.1651, reg1: 2513.6777, reg2: 1056.0375, VOL_CONS_UPPER_LOSS: 1.6037, VOL_CONS_LOWER_LOSS: 1.5491\n",
      "Epoch 27000/60000, Loss: 498581.2589, WAPE: 0.1769, WAPE_TEST: 0.1790, WAPE_VOL: 0.1633, WAPE_VOL_TEST: 0.1644, reg1: 2486.2604, reg2: 1073.0393, VOL_CONS_UPPER_LOSS: 0.3587, VOL_CONS_LOWER_LOSS: 1.5890\n",
      "Epoch 27250/60000, Loss: 509701.6686, WAPE: 0.1783, WAPE_TEST: 0.1772, WAPE_VOL: 0.1650, WAPE_VOL_TEST: 0.1650, reg1: 2483.2668, reg2: 1016.3918, VOL_CONS_UPPER_LOSS: 10.9823, VOL_CONS_LOWER_LOSS: 1.4683\n",
      "Epoch 27500/60000, Loss: 572758.8172, WAPE: 0.1918, WAPE_TEST: 0.1896, WAPE_VOL: 0.1828, WAPE_VOL_TEST: 0.1835, reg1: 2611.8423, reg2: 1147.6456, VOL_CONS_UPPER_LOSS: 0.0090, VOL_CONS_LOWER_LOSS: 1.9169\n",
      "Epoch 27750/60000, Loss: 855729.8571, WAPE: 0.2023, WAPE_TEST: 0.2007, WAPE_VOL: 0.2157, WAPE_VOL_TEST: 0.2036, reg1: 3123.1750, reg2: 1220.1533, VOL_CONS_UPPER_LOSS: 62.6771, VOL_CONS_LOWER_LOSS: 4.0606\n",
      "Epoch 28000/60000, Loss: 519059.2627, WAPE: 0.1868, WAPE_TEST: 0.1838, WAPE_VOL: 0.1752, WAPE_VOL_TEST: 0.1717, reg1: 2547.7986, reg2: 1057.5013, VOL_CONS_UPPER_LOSS: 1.7943, VOL_CONS_LOWER_LOSS: 1.1465\n",
      "Epoch 28250/60000, Loss: 532187.3127, WAPE: 0.1807, WAPE_TEST: 0.1813, WAPE_VOL: 0.1700, WAPE_VOL_TEST: 0.1692, reg1: 2637.6323, reg2: 991.4046, VOL_CONS_UPPER_LOSS: 15.9177, VOL_CONS_LOWER_LOSS: 1.4255\n",
      "Epoch 28500/60000, Loss: 566883.6992, WAPE: 0.1827, WAPE_TEST: 0.1812, WAPE_VOL: 0.1806, WAPE_VOL_TEST: 0.1796, reg1: 2622.7585, reg2: 1001.0967, VOL_CONS_UPPER_LOSS: 4.4148, VOL_CONS_LOWER_LOSS: 2.3429\n",
      "Epoch 28750/60000, Loss: 504751.4565, WAPE: 0.1795, WAPE_TEST: 0.1780, WAPE_VOL: 0.1660, WAPE_VOL_TEST: 0.1649, reg1: 2555.2295, reg2: 1020.0358, VOL_CONS_UPPER_LOSS: 0.1536, VOL_CONS_LOWER_LOSS: 1.3390\n",
      "Epoch 29000/60000, Loss: 529231.6922, WAPE: 0.1850, WAPE_TEST: 0.1803, WAPE_VOL: 0.1699, WAPE_VOL_TEST: 0.1689, reg1: 2545.9374, reg2: 1005.7197, VOL_CONS_UPPER_LOSS: 0.9990, VOL_CONS_LOWER_LOSS: 2.1995\n",
      "Epoch 29250/60000, Loss: 551665.7922, WAPE: 0.1833, WAPE_TEST: 0.1849, WAPE_VOL: 0.1781, WAPE_VOL_TEST: 0.1775, reg1: 2573.6174, reg2: 1089.9997, VOL_CONS_UPPER_LOSS: 30.6520, VOL_CONS_LOWER_LOSS: 1.5634\n",
      "Epoch 29500/60000, Loss: 500717.2931, WAPE: 0.1790, WAPE_TEST: 0.1773, WAPE_VOL: 0.1638, WAPE_VOL_TEST: 0.1649, reg1: 2502.2105, reg2: 1019.7047, VOL_CONS_UPPER_LOSS: 0.4735, VOL_CONS_LOWER_LOSS: 1.4361\n",
      "Epoch 29750/60000, Loss: 636195.8224, WAPE: 0.1905, WAPE_TEST: 0.1888, WAPE_VOL: 0.1826, WAPE_VOL_TEST: 0.1913, reg1: 2574.1839, reg2: 1160.1756, VOL_CONS_UPPER_LOSS: 0.0545, VOL_CONS_LOWER_LOSS: 1.5269\n",
      "Epoch 30000/60000, Loss: 497717.1046, WAPE: 0.1775, WAPE_TEST: 0.1775, WAPE_VOL: 0.1640, WAPE_VOL_TEST: 0.1627, reg1: 2481.6115, reg2: 1036.4044, VOL_CONS_UPPER_LOSS: 0.2174, VOL_CONS_LOWER_LOSS: 1.4743\n",
      "Epoch 30250/60000, Loss: 519762.6295, WAPE: 0.1778, WAPE_TEST: 0.1769, WAPE_VOL: 0.1674, WAPE_VOL_TEST: 0.1680, reg1: 2483.7426, reg2: 1028.4457, VOL_CONS_UPPER_LOSS: 8.3154, VOL_CONS_LOWER_LOSS: 1.4925\n",
      "Epoch 30500/60000, Loss: 515604.6649, WAPE: 0.1766, WAPE_TEST: 0.1782, WAPE_VOL: 0.1661, WAPE_VOL_TEST: 0.1654, reg1: 2523.5477, reg2: 1034.9219, VOL_CONS_UPPER_LOSS: 16.4529, VOL_CONS_LOWER_LOSS: 1.4389\n",
      "Epoch 30750/60000, Loss: 519569.0852, WAPE: 0.1778, WAPE_TEST: 0.1816, WAPE_VOL: 0.1737, WAPE_VOL_TEST: 0.1747, reg1: 2488.6790, reg2: 1122.9524, VOL_CONS_UPPER_LOSS: 0.0170, VOL_CONS_LOWER_LOSS: 1.9331\n",
      "Epoch 31000/60000, Loss: 497383.7692, WAPE: 0.1763, WAPE_TEST: 0.1787, WAPE_VOL: 0.1623, WAPE_VOL_TEST: 0.1641, reg1: 2455.4236, reg2: 1061.5502, VOL_CONS_UPPER_LOSS: 0.0494, VOL_CONS_LOWER_LOSS: 1.3823\n",
      "Epoch 31250/60000, Loss: 557356.7409, WAPE: 0.1931, WAPE_TEST: 0.1822, WAPE_VOL: 0.1920, WAPE_VOL_TEST: 0.1844, reg1: 2513.4136, reg2: 1078.6763, VOL_CONS_UPPER_LOSS: 0.6867, VOL_CONS_LOWER_LOSS: 0.7314\n",
      "Epoch 31500/60000, Loss: 510805.5574, WAPE: 0.1757, WAPE_TEST: 0.1787, WAPE_VOL: 0.1689, WAPE_VOL_TEST: 0.1686, reg1: 2467.5843, reg2: 1085.2828, VOL_CONS_UPPER_LOSS: 14.7413, VOL_CONS_LOWER_LOSS: 1.6524\n",
      "Epoch 31750/60000, Loss: 506794.3104, WAPE: 0.1772, WAPE_TEST: 0.1792, WAPE_VOL: 0.1717, WAPE_VOL_TEST: 0.1704, reg1: 2518.7002, reg2: 1063.6759, VOL_CONS_UPPER_LOSS: 0.5072, VOL_CONS_LOWER_LOSS: 2.9054\n",
      "Epoch 32000/60000, Loss: 500844.4039, WAPE: 0.1778, WAPE_TEST: 0.1785, WAPE_VOL: 0.1670, WAPE_VOL_TEST: 0.1647, reg1: 2472.6817, reg2: 1038.6946, VOL_CONS_UPPER_LOSS: 8.6485, VOL_CONS_LOWER_LOSS: 1.1505\n",
      "Epoch 32250/60000, Loss: 489415.1247, WAPE: 0.1759, WAPE_TEST: 0.1764, WAPE_VOL: 0.1627, WAPE_VOL_TEST: 0.1626, reg1: 2414.6982, reg2: 1102.0315, VOL_CONS_UPPER_LOSS: 0.2203, VOL_CONS_LOWER_LOSS: 1.5646\n",
      "Epoch 32500/60000, Loss: 491591.5786, WAPE: 0.1755, WAPE_TEST: 0.1772, WAPE_VOL: 0.1622, WAPE_VOL_TEST: 0.1628, reg1: 2479.5648, reg2: 1056.1502, VOL_CONS_UPPER_LOSS: 0.7768, VOL_CONS_LOWER_LOSS: 1.7445\n",
      "Epoch 32750/60000, Loss: 507515.3542, WAPE: 0.1774, WAPE_TEST: 0.1873, WAPE_VOL: 0.1665, WAPE_VOL_TEST: 0.1751, reg1: 2479.3250, reg2: 1121.0004, VOL_CONS_UPPER_LOSS: 0.0079, VOL_CONS_LOWER_LOSS: 1.0209\n",
      "Epoch 33000/60000, Loss: 494217.0068, WAPE: 0.1787, WAPE_TEST: 0.1761, WAPE_VOL: 0.1627, WAPE_VOL_TEST: 0.1611, reg1: 2468.5451, reg2: 1062.0893, VOL_CONS_UPPER_LOSS: 0.2292, VOL_CONS_LOWER_LOSS: 1.4611\n",
      "Epoch 33250/60000, Loss: 532629.4091, WAPE: 0.1813, WAPE_TEST: 0.1807, WAPE_VOL: 0.1654, WAPE_VOL_TEST: 0.1704, reg1: 2461.0880, reg2: 1045.4103, VOL_CONS_UPPER_LOSS: 1.9088, VOL_CONS_LOWER_LOSS: 1.5282\n",
      "Epoch 33500/60000, Loss: 497679.7538, WAPE: 0.1809, WAPE_TEST: 0.1764, WAPE_VOL: 0.1652, WAPE_VOL_TEST: 0.1627, reg1: 2506.0287, reg2: 1105.2741, VOL_CONS_UPPER_LOSS: 0.2764, VOL_CONS_LOWER_LOSS: 1.6830\n",
      "Epoch 33750/60000, Loss: 534552.0680, WAPE: 0.1856, WAPE_TEST: 0.1798, WAPE_VOL: 0.1739, WAPE_VOL_TEST: 0.1647, reg1: 2542.9955, reg2: 1056.4113, VOL_CONS_UPPER_LOSS: 0.0200, VOL_CONS_LOWER_LOSS: 2.0665\n",
      "Epoch 34000/60000, Loss: 597776.4348, WAPE: 0.1777, WAPE_TEST: 0.1838, WAPE_VOL: 0.1747, WAPE_VOL_TEST: 0.1713, reg1: 2592.5057, reg2: 1070.8770, VOL_CONS_UPPER_LOSS: 40.9273, VOL_CONS_LOWER_LOSS: 2.2307\n",
      "Epoch 34250/60000, Loss: 626936.7286, WAPE: 0.1881, WAPE_TEST: 0.1873, WAPE_VOL: 0.2084, WAPE_VOL_TEST: 0.1967, reg1: 2836.7226, reg2: 1478.0985, VOL_CONS_UPPER_LOSS: 0.0226, VOL_CONS_LOWER_LOSS: 2.0866\n",
      "Epoch 34500/60000, Loss: 495060.9806, WAPE: 0.1755, WAPE_TEST: 0.1771, WAPE_VOL: 0.1623, WAPE_VOL_TEST: 0.1626, reg1: 2560.0278, reg2: 1157.6033, VOL_CONS_UPPER_LOSS: 0.2782, VOL_CONS_LOWER_LOSS: 1.7020\n",
      "Epoch 34750/60000, Loss: 490871.2375, WAPE: 0.1758, WAPE_TEST: 0.1774, WAPE_VOL: 0.1604, WAPE_VOL_TEST: 0.1621, reg1: 2557.9418, reg2: 1085.5003, VOL_CONS_UPPER_LOSS: 0.1599, VOL_CONS_LOWER_LOSS: 1.6827\n",
      "Epoch 35000/60000, Loss: 494510.3858, WAPE: 0.1749, WAPE_TEST: 0.1772, WAPE_VOL: 0.1610, WAPE_VOL_TEST: 0.1625, reg1: 2586.3261, reg2: 1059.7742, VOL_CONS_UPPER_LOSS: 2.7806, VOL_CONS_LOWER_LOSS: 1.8274\n",
      "Epoch 35250/60000, Loss: 502650.3305, WAPE: 0.1757, WAPE_TEST: 0.1762, WAPE_VOL: 0.1634, WAPE_VOL_TEST: 0.1628, reg1: 2611.5727, reg2: 1075.0695, VOL_CONS_UPPER_LOSS: 11.3084, VOL_CONS_LOWER_LOSS: 1.6719\n",
      "Epoch 35500/60000, Loss: 504314.3446, WAPE: 0.1738, WAPE_TEST: 0.1748, WAPE_VOL: 0.1624, WAPE_VOL_TEST: 0.1624, reg1: 2522.6580, reg2: 1105.6588, VOL_CONS_UPPER_LOSS: 14.6233, VOL_CONS_LOWER_LOSS: 1.6858\n",
      "Epoch 35750/60000, Loss: 652132.6820, WAPE: 0.1907, WAPE_TEST: 0.1907, WAPE_VOL: 0.2030, WAPE_VOL_TEST: 0.1907, reg1: 2769.3210, reg2: 1285.7994, VOL_CONS_UPPER_LOSS: 0.0271, VOL_CONS_LOWER_LOSS: 20.1547\n",
      "Epoch 36000/60000, Loss: 491357.1011, WAPE: 0.1746, WAPE_TEST: 0.1758, WAPE_VOL: 0.1614, WAPE_VOL_TEST: 0.1615, reg1: 2641.7285, reg2: 1124.3496, VOL_CONS_UPPER_LOSS: 0.7237, VOL_CONS_LOWER_LOSS: 1.6574\n",
      "Epoch 36250/60000, Loss: 582876.1288, WAPE: 0.1768, WAPE_TEST: 0.1811, WAPE_VOL: 0.1740, WAPE_VOL_TEST: 0.1795, reg1: 2628.4180, reg2: 1113.3150, VOL_CONS_UPPER_LOSS: 36.0314, VOL_CONS_LOWER_LOSS: 3.6574\n",
      "Epoch 36500/60000, Loss: 493876.2556, WAPE: 0.1735, WAPE_TEST: 0.1783, WAPE_VOL: 0.1627, WAPE_VOL_TEST: 0.1640, reg1: 2615.1459, reg2: 1073.5389, VOL_CONS_UPPER_LOSS: 0.0845, VOL_CONS_LOWER_LOSS: 1.9095\n",
      "Epoch 36750/60000, Loss: 494146.0502, WAPE: 0.1787, WAPE_TEST: 0.1779, WAPE_VOL: 0.1667, WAPE_VOL_TEST: 0.1624, reg1: 2628.4187, reg2: 1074.3279, VOL_CONS_UPPER_LOSS: 0.1227, VOL_CONS_LOWER_LOSS: 1.4959\n",
      "Epoch 37000/60000, Loss: 523898.5082, WAPE: 0.1801, WAPE_TEST: 0.1806, WAPE_VOL: 0.1692, WAPE_VOL_TEST: 0.1692, reg1: 2732.7125, reg2: 1613.4850, VOL_CONS_UPPER_LOSS: 0.2190, VOL_CONS_LOWER_LOSS: 3.1525\n",
      "Epoch 37250/60000, Loss: 528908.8944, WAPE: 0.1825, WAPE_TEST: 0.1826, WAPE_VOL: 0.1703, WAPE_VOL_TEST: 0.1700, reg1: 2586.8082, reg2: 1398.7676, VOL_CONS_UPPER_LOSS: 0.5426, VOL_CONS_LOWER_LOSS: 3.1161\n",
      "Epoch 37500/60000, Loss: 493811.2551, WAPE: 0.1778, WAPE_TEST: 0.1763, WAPE_VOL: 0.1628, WAPE_VOL_TEST: 0.1616, reg1: 2661.1898, reg2: 1144.5829, VOL_CONS_UPPER_LOSS: 0.8453, VOL_CONS_LOWER_LOSS: 1.7172\n",
      "Epoch 37750/60000, Loss: 491321.0835, WAPE: 0.1757, WAPE_TEST: 0.1756, WAPE_VOL: 0.1613, WAPE_VOL_TEST: 0.1609, reg1: 2635.0533, reg2: 1088.0361, VOL_CONS_UPPER_LOSS: 0.5284, VOL_CONS_LOWER_LOSS: 1.5616\n",
      "Epoch 38000/60000, Loss: 490662.3921, WAPE: 0.1765, WAPE_TEST: 0.1765, WAPE_VOL: 0.1618, WAPE_VOL_TEST: 0.1612, reg1: 2625.5857, reg2: 1062.9122, VOL_CONS_UPPER_LOSS: 0.8498, VOL_CONS_LOWER_LOSS: 1.4397\n",
      "Epoch 38250/60000, Loss: 496126.0904, WAPE: 0.1766, WAPE_TEST: 0.1763, WAPE_VOL: 0.1620, WAPE_VOL_TEST: 0.1613, reg1: 2606.6102, reg2: 1083.6168, VOL_CONS_UPPER_LOSS: 0.1722, VOL_CONS_LOWER_LOSS: 1.5443\n",
      "Epoch 38500/60000, Loss: 503901.0155, WAPE: 0.1775, WAPE_TEST: 0.1750, WAPE_VOL: 0.1658, WAPE_VOL_TEST: 0.1631, reg1: 2605.1249, reg2: 1082.1535, VOL_CONS_UPPER_LOSS: 1.9217, VOL_CONS_LOWER_LOSS: 1.4504\n",
      "Epoch 38750/60000, Loss: 520398.2564, WAPE: 0.1787, WAPE_TEST: 0.1814, WAPE_VOL: 0.1632, WAPE_VOL_TEST: 0.1643, reg1: 2602.7397, reg2: 1120.9186, VOL_CONS_UPPER_LOSS: 0.0275, VOL_CONS_LOWER_LOSS: 4.8639\n",
      "Epoch 39000/60000, Loss: 505700.2169, WAPE: 0.1754, WAPE_TEST: 0.1788, WAPE_VOL: 0.1672, WAPE_VOL_TEST: 0.1690, reg1: 2617.7472, reg2: 1119.9057, VOL_CONS_UPPER_LOSS: 0.0474, VOL_CONS_LOWER_LOSS: 1.9767\n",
      "Epoch 39250/60000, Loss: 501241.5504, WAPE: 0.1797, WAPE_TEST: 0.1755, WAPE_VOL: 0.1660, WAPE_VOL_TEST: 0.1634, reg1: 2587.0940, reg2: 1082.6617, VOL_CONS_UPPER_LOSS: 0.0520, VOL_CONS_LOWER_LOSS: 1.7875\n",
      "Epoch 39500/60000, Loss: 565941.2753, WAPE: 0.1803, WAPE_TEST: 0.1773, WAPE_VOL: 0.1687, WAPE_VOL_TEST: 0.1640, reg1: 2668.8940, reg2: 1095.6791, VOL_CONS_UPPER_LOSS: 0.7190, VOL_CONS_LOWER_LOSS: 2.6999\n",
      "Epoch 39750/60000, Loss: 500457.9055, WAPE: 0.1746, WAPE_TEST: 0.1767, WAPE_VOL: 0.1655, WAPE_VOL_TEST: 0.1662, reg1: 2664.1516, reg2: 1131.5940, VOL_CONS_UPPER_LOSS: 7.1301, VOL_CONS_LOWER_LOSS: 1.2872\n",
      "Epoch 40000/60000, Loss: 499125.9936, WAPE: 0.1770, WAPE_TEST: 0.1763, WAPE_VOL: 0.1669, WAPE_VOL_TEST: 0.1675, reg1: 2655.2269, reg2: 1120.7227, VOL_CONS_UPPER_LOSS: 0.3111, VOL_CONS_LOWER_LOSS: 2.0459\n",
      "Epoch 40250/60000, Loss: 491427.3095, WAPE: 0.1747, WAPE_TEST: 0.1763, WAPE_VOL: 0.1610, WAPE_VOL_TEST: 0.1628, reg1: 2577.6825, reg2: 1116.8314, VOL_CONS_UPPER_LOSS: 4.4994, VOL_CONS_LOWER_LOSS: 1.4449\n",
      "Epoch 40500/60000, Loss: 619988.5016, WAPE: 0.1912, WAPE_TEST: 0.1992, WAPE_VOL: 0.2021, WAPE_VOL_TEST: 0.2132, reg1: 2611.0463, reg2: 1149.1493, VOL_CONS_UPPER_LOSS: 0.0043, VOL_CONS_LOWER_LOSS: 8.9427\n",
      "Epoch 40750/60000, Loss: 487871.3773, WAPE: 0.1751, WAPE_TEST: 0.1738, WAPE_VOL: 0.1615, WAPE_VOL_TEST: 0.1617, reg1: 2557.3038, reg2: 1110.7727, VOL_CONS_UPPER_LOSS: 1.5204, VOL_CONS_LOWER_LOSS: 1.7727\n",
      "Epoch 41000/60000, Loss: 504142.1574, WAPE: 0.1761, WAPE_TEST: 0.1738, WAPE_VOL: 0.1641, WAPE_VOL_TEST: 0.1639, reg1: 2557.9343, reg2: 1066.9874, VOL_CONS_UPPER_LOSS: 4.5574, VOL_CONS_LOWER_LOSS: 1.7854\n",
      "Epoch 41250/60000, Loss: 549521.2152, WAPE: 0.1803, WAPE_TEST: 0.1771, WAPE_VOL: 0.1803, WAPE_VOL_TEST: 0.1780, reg1: 2582.5636, reg2: 1096.0384, VOL_CONS_UPPER_LOSS: 1.3389, VOL_CONS_LOWER_LOSS: 1.9480\n",
      "Epoch 41500/60000, Loss: 494994.1913, WAPE: 0.1776, WAPE_TEST: 0.1739, WAPE_VOL: 0.1652, WAPE_VOL_TEST: 0.1616, reg1: 2567.8392, reg2: 1137.5716, VOL_CONS_UPPER_LOSS: 5.5393, VOL_CONS_LOWER_LOSS: 1.0864\n",
      "Epoch 41750/60000, Loss: 485365.7653, WAPE: 0.1740, WAPE_TEST: 0.1742, WAPE_VOL: 0.1605, WAPE_VOL_TEST: 0.1602, reg1: 2556.5416, reg2: 1060.8593, VOL_CONS_UPPER_LOSS: 0.6726, VOL_CONS_LOWER_LOSS: 1.6025\n",
      "Epoch 42000/60000, Loss: 494474.9588, WAPE: 0.1752, WAPE_TEST: 0.1766, WAPE_VOL: 0.1616, WAPE_VOL_TEST: 0.1622, reg1: 2564.8631, reg2: 1150.1060, VOL_CONS_UPPER_LOSS: 0.5519, VOL_CONS_LOWER_LOSS: 1.6901\n",
      "Epoch 42250/60000, Loss: 496535.1595, WAPE: 0.1757, WAPE_TEST: 0.1757, WAPE_VOL: 0.1606, WAPE_VOL_TEST: 0.1623, reg1: 2612.2757, reg2: 1089.4644, VOL_CONS_UPPER_LOSS: 0.6962, VOL_CONS_LOWER_LOSS: 1.6967\n",
      "Epoch 42500/60000, Loss: 531926.8619, WAPE: 0.1810, WAPE_TEST: 0.1809, WAPE_VOL: 0.1703, WAPE_VOL_TEST: 0.1660, reg1: 2620.0090, reg2: 1135.1857, VOL_CONS_UPPER_LOSS: 0.0049, VOL_CONS_LOWER_LOSS: 1.9367\n",
      "Epoch 42750/60000, Loss: 494699.0404, WAPE: 0.1752, WAPE_TEST: 0.1754, WAPE_VOL: 0.1623, WAPE_VOL_TEST: 0.1642, reg1: 2577.5242, reg2: 1095.3025, VOL_CONS_UPPER_LOSS: 0.1974, VOL_CONS_LOWER_LOSS: 1.7958\n",
      "Epoch 43000/60000, Loss: 915006.0306, WAPE: 0.1882, WAPE_TEST: 0.1908, WAPE_VOL: 0.2061, WAPE_VOL_TEST: 0.2003, reg1: 2626.1061, reg2: 1116.5598, VOL_CONS_UPPER_LOSS: 53.8933, VOL_CONS_LOWER_LOSS: 213.6019\n",
      "Epoch 43250/60000, Loss: 486872.8485, WAPE: 0.1741, WAPE_TEST: 0.1743, WAPE_VOL: 0.1609, WAPE_VOL_TEST: 0.1610, reg1: 2563.5028, reg2: 1124.9503, VOL_CONS_UPPER_LOSS: 0.4380, VOL_CONS_LOWER_LOSS: 1.6299\n",
      "Epoch 43500/60000, Loss: 559611.5808, WAPE: 0.1794, WAPE_TEST: 0.1765, WAPE_VOL: 0.1685, WAPE_VOL_TEST: 0.1652, reg1: 2586.7924, reg2: 1073.0959, VOL_CONS_UPPER_LOSS: 0.0383, VOL_CONS_LOWER_LOSS: 1.8313\n",
      "Epoch 43750/60000, Loss: 578070.7506, WAPE: 0.1768, WAPE_TEST: 0.1803, WAPE_VOL: 0.1759, WAPE_VOL_TEST: 0.1751, reg1: 2611.8505, reg2: 1110.7420, VOL_CONS_UPPER_LOSS: 46.2169, VOL_CONS_LOWER_LOSS: 0.9989\n",
      "Epoch 44000/60000, Loss: 497391.8851, WAPE: 0.1747, WAPE_TEST: 0.1787, WAPE_VOL: 0.1616, WAPE_VOL_TEST: 0.1640, reg1: 2534.2217, reg2: 1099.2978, VOL_CONS_UPPER_LOSS: 0.0309, VOL_CONS_LOWER_LOSS: 1.9239\n",
      "Epoch 44250/60000, Loss: 495986.1229, WAPE: 0.1763, WAPE_TEST: 0.1761, WAPE_VOL: 0.1630, WAPE_VOL_TEST: 0.1609, reg1: 2593.8407, reg2: 1146.2612, VOL_CONS_UPPER_LOSS: 0.0197, VOL_CONS_LOWER_LOSS: 1.8315\n",
      "Epoch 44500/60000, Loss: 496293.4173, WAPE: 0.1777, WAPE_TEST: 0.1733, WAPE_VOL: 0.1649, WAPE_VOL_TEST: 0.1622, reg1: 2529.9356, reg2: 1095.2479, VOL_CONS_UPPER_LOSS: 0.0362, VOL_CONS_LOWER_LOSS: 1.5669\n",
      "Epoch 44750/60000, Loss: 485734.1626, WAPE: 0.1739, WAPE_TEST: 0.1730, WAPE_VOL: 0.1605, WAPE_VOL_TEST: 0.1607, reg1: 2548.6213, reg2: 1055.3595, VOL_CONS_UPPER_LOSS: 0.3298, VOL_CONS_LOWER_LOSS: 1.7398\n",
      "Epoch 45000/60000, Loss: 490896.9767, WAPE: 0.1730, WAPE_TEST: 0.1766, WAPE_VOL: 0.1607, WAPE_VOL_TEST: 0.1627, reg1: 2504.3450, reg2: 1116.4151, VOL_CONS_UPPER_LOSS: 3.5834, VOL_CONS_LOWER_LOSS: 2.0138\n",
      "Epoch 45250/60000, Loss: 628104.1367, WAPE: 0.1796, WAPE_TEST: 0.1788, WAPE_VOL: 0.1768, WAPE_VOL_TEST: 0.1709, reg1: 2635.3462, reg2: 1146.0616, VOL_CONS_UPPER_LOSS: 55.1540, VOL_CONS_LOWER_LOSS: 1.6985\n",
      "Epoch 45500/60000, Loss: 485594.9590, WAPE: 0.1743, WAPE_TEST: 0.1741, WAPE_VOL: 0.1609, WAPE_VOL_TEST: 0.1605, reg1: 2583.2979, reg2: 1119.7105, VOL_CONS_UPPER_LOSS: 1.3238, VOL_CONS_LOWER_LOSS: 1.4097\n",
      "Epoch 45750/60000, Loss: 506972.9728, WAPE: 0.1762, WAPE_TEST: 0.1763, WAPE_VOL: 0.1642, WAPE_VOL_TEST: 0.1630, reg1: 2786.6293, reg2: 1115.1153, VOL_CONS_UPPER_LOSS: 0.0428, VOL_CONS_LOWER_LOSS: 1.5874\n",
      "Epoch 46000/60000, Loss: 497714.9347, WAPE: 0.1761, WAPE_TEST: 0.1770, WAPE_VOL: 0.1626, WAPE_VOL_TEST: 0.1628, reg1: 2643.3268, reg2: 1084.5483, VOL_CONS_UPPER_LOSS: 0.2522, VOL_CONS_LOWER_LOSS: 1.9893\n",
      "Epoch 46250/60000, Loss: 502466.9502, WAPE: 0.1755, WAPE_TEST: 0.1775, WAPE_VOL: 0.1640, WAPE_VOL_TEST: 0.1660, reg1: 2598.5000, reg2: 1089.2604, VOL_CONS_UPPER_LOSS: 0.1651, VOL_CONS_LOWER_LOSS: 1.8308\n",
      "Epoch 46500/60000, Loss: 514318.5214, WAPE: 0.1792, WAPE_TEST: 0.1760, WAPE_VOL: 0.1650, WAPE_VOL_TEST: 0.1655, reg1: 2583.8657, reg2: 1079.6959, VOL_CONS_UPPER_LOSS: 0.8883, VOL_CONS_LOWER_LOSS: 1.8017\n",
      "Epoch 46750/60000, Loss: 506689.6991, WAPE: 0.1757, WAPE_TEST: 0.1740, WAPE_VOL: 0.1664, WAPE_VOL_TEST: 0.1690, reg1: 2573.5489, reg2: 1126.3444, VOL_CONS_UPPER_LOSS: 0.3733, VOL_CONS_LOWER_LOSS: 1.5984\n",
      "Epoch 47000/60000, Loss: 528026.0878, WAPE: 0.1766, WAPE_TEST: 0.1764, WAPE_VOL: 0.1655, WAPE_VOL_TEST: 0.1632, reg1: 2585.7612, reg2: 1099.9474, VOL_CONS_UPPER_LOSS: 0.0051, VOL_CONS_LOWER_LOSS: 1.7888\n",
      "Epoch 47250/60000, Loss: 490671.0517, WAPE: 0.1759, WAPE_TEST: 0.1772, WAPE_VOL: 0.1622, WAPE_VOL_TEST: 0.1640, reg1: 2551.7295, reg2: 1124.2252, VOL_CONS_UPPER_LOSS: 0.2222, VOL_CONS_LOWER_LOSS: 1.4967\n",
      "Epoch 47500/60000, Loss: 504918.9702, WAPE: 0.1788, WAPE_TEST: 0.1780, WAPE_VOL: 0.1695, WAPE_VOL_TEST: 0.1701, reg1: 2641.3537, reg2: 1176.6413, VOL_CONS_UPPER_LOSS: 0.3390, VOL_CONS_LOWER_LOSS: 1.7497\n",
      "Epoch 47750/60000, Loss: 502502.5564, WAPE: 0.1774, WAPE_TEST: 0.1775, WAPE_VOL: 0.1630, WAPE_VOL_TEST: 0.1632, reg1: 2738.7643, reg2: 1113.8341, VOL_CONS_UPPER_LOSS: 9.4177, VOL_CONS_LOWER_LOSS: 1.4335\n",
      "Epoch 48000/60000, Loss: 521162.0676, WAPE: 0.1782, WAPE_TEST: 0.1785, WAPE_VOL: 0.1640, WAPE_VOL_TEST: 0.1665, reg1: 2648.3754, reg2: 1121.1802, VOL_CONS_UPPER_LOSS: 0.6400, VOL_CONS_LOWER_LOSS: 1.9854\n",
      "Epoch 48250/60000, Loss: 492602.8609, WAPE: 0.1754, WAPE_TEST: 0.1760, WAPE_VOL: 0.1622, WAPE_VOL_TEST: 0.1621, reg1: 2611.2638, reg2: 1139.4468, VOL_CONS_UPPER_LOSS: 0.1528, VOL_CONS_LOWER_LOSS: 1.3945\n",
      "Epoch 48500/60000, Loss: 503516.2101, WAPE: 0.1770, WAPE_TEST: 0.1787, WAPE_VOL: 0.1618, WAPE_VOL_TEST: 0.1648, reg1: 2592.7703, reg2: 1098.3241, VOL_CONS_UPPER_LOSS: 0.0646, VOL_CONS_LOWER_LOSS: 1.6967\n",
      "Epoch 48750/60000, Loss: 776349.6235, WAPE: 0.2056, WAPE_TEST: 0.2280, WAPE_VOL: 0.2127, WAPE_VOL_TEST: 0.2765, reg1: 2635.4109, reg2: 1112.9788, VOL_CONS_UPPER_LOSS: 59.8622, VOL_CONS_LOWER_LOSS: 2.3080\n",
      "Epoch 49000/60000, Loss: 512406.6152, WAPE: 0.1814, WAPE_TEST: 0.1826, WAPE_VOL: 0.1700, WAPE_VOL_TEST: 0.1708, reg1: 2625.6138, reg2: 1143.0365, VOL_CONS_UPPER_LOSS: 0.7920, VOL_CONS_LOWER_LOSS: 2.3124\n",
      "Epoch 49250/60000, Loss: 510068.2158, WAPE: 0.1809, WAPE_TEST: 0.1814, WAPE_VOL: 0.1695, WAPE_VOL_TEST: 0.1689, reg1: 2538.4483, reg2: 1118.5395, VOL_CONS_UPPER_LOSS: 0.5658, VOL_CONS_LOWER_LOSS: 2.7248\n",
      "Epoch 49500/60000, Loss: 506661.6107, WAPE: 0.1798, WAPE_TEST: 0.1794, WAPE_VOL: 0.1685, WAPE_VOL_TEST: 0.1674, reg1: 2610.1540, reg2: 1092.7334, VOL_CONS_UPPER_LOSS: 1.0465, VOL_CONS_LOWER_LOSS: 2.0851\n",
      "Epoch 49750/60000, Loss: 545228.8935, WAPE: 0.1810, WAPE_TEST: 0.1828, WAPE_VOL: 0.1708, WAPE_VOL_TEST: 0.1727, reg1: 2617.9670, reg2: 1057.8543, VOL_CONS_UPPER_LOSS: 0.0041, VOL_CONS_LOWER_LOSS: 2.2133\n",
      "Epoch 50000/60000, Loss: 503030.6371, WAPE: 0.1793, WAPE_TEST: 0.1789, WAPE_VOL: 0.1669, WAPE_VOL_TEST: 0.1671, reg1: 2560.9544, reg2: 1089.1650, VOL_CONS_UPPER_LOSS: 1.1447, VOL_CONS_LOWER_LOSS: 1.9459\n",
      "Epoch 50250/60000, Loss: 504253.4811, WAPE: 0.1792, WAPE_TEST: 0.1786, WAPE_VOL: 0.1665, WAPE_VOL_TEST: 0.1668, reg1: 2553.1853, reg2: 1103.0189, VOL_CONS_UPPER_LOSS: 0.3421, VOL_CONS_LOWER_LOSS: 1.7407\n",
      "Epoch 50500/60000, Loss: 510864.3273, WAPE: 0.1833, WAPE_TEST: 0.1780, WAPE_VOL: 0.1707, WAPE_VOL_TEST: 0.1669, reg1: 2561.1818, reg2: 1065.2919, VOL_CONS_UPPER_LOSS: 4.4973, VOL_CONS_LOWER_LOSS: 1.8059\n",
      "Epoch 50750/60000, Loss: 496246.4758, WAPE: 0.1787, WAPE_TEST: 0.1782, WAPE_VOL: 0.1634, WAPE_VOL_TEST: 0.1645, reg1: 2544.7297, reg2: 1076.1523, VOL_CONS_UPPER_LOSS: 0.4985, VOL_CONS_LOWER_LOSS: 1.8579\n",
      "Epoch 51000/60000, Loss: 496975.4022, WAPE: 0.1771, WAPE_TEST: 0.1783, WAPE_VOL: 0.1637, WAPE_VOL_TEST: 0.1642, reg1: 2546.3856, reg2: 1077.5594, VOL_CONS_UPPER_LOSS: 0.0689, VOL_CONS_LOWER_LOSS: 2.2545\n",
      "Epoch 51250/60000, Loss: 501794.7141, WAPE: 0.1809, WAPE_TEST: 0.1757, WAPE_VOL: 0.1682, WAPE_VOL_TEST: 0.1639, reg1: 2523.4193, reg2: 1089.3700, VOL_CONS_UPPER_LOSS: 0.5124, VOL_CONS_LOWER_LOSS: 1.7200\n",
      "Epoch 51500/60000, Loss: 506685.1100, WAPE: 0.1777, WAPE_TEST: 0.1787, WAPE_VOL: 0.1647, WAPE_VOL_TEST: 0.1645, reg1: 2524.2849, reg2: 1081.9537, VOL_CONS_UPPER_LOSS: 0.0094, VOL_CONS_LOWER_LOSS: 1.5142\n",
      "Epoch 51750/60000, Loss: 539250.1015, WAPE: 0.1829, WAPE_TEST: 0.1837, WAPE_VOL: 0.1684, WAPE_VOL_TEST: 0.1687, reg1: 2489.9187, reg2: 1067.9145, VOL_CONS_UPPER_LOSS: 0.0169, VOL_CONS_LOWER_LOSS: 5.6598\n",
      "Epoch 52000/60000, Loss: 503420.9288, WAPE: 0.1792, WAPE_TEST: 0.1782, WAPE_VOL: 0.1654, WAPE_VOL_TEST: 0.1638, reg1: 2511.0000, reg2: 1084.5663, VOL_CONS_UPPER_LOSS: 0.4634, VOL_CONS_LOWER_LOSS: 1.7319\n",
      "Epoch 52250/60000, Loss: 514984.7908, WAPE: 0.1757, WAPE_TEST: 0.1789, WAPE_VOL: 0.1643, WAPE_VOL_TEST: 0.1643, reg1: 2495.5044, reg2: 1074.3037, VOL_CONS_UPPER_LOSS: 8.5563, VOL_CONS_LOWER_LOSS: 2.1686\n",
      "Epoch 52500/60000, Loss: 504772.2035, WAPE: 0.1797, WAPE_TEST: 0.1782, WAPE_VOL: 0.1678, WAPE_VOL_TEST: 0.1664, reg1: 2516.2141, reg2: 1138.6048, VOL_CONS_UPPER_LOSS: 0.3579, VOL_CONS_LOWER_LOSS: 3.8600\n",
      "Epoch 52750/60000, Loss: 516928.9592, WAPE: 0.1782, WAPE_TEST: 0.1790, WAPE_VOL: 0.1670, WAPE_VOL_TEST: 0.1673, reg1: 2653.5106, reg2: 1092.9168, VOL_CONS_UPPER_LOSS: 9.2166, VOL_CONS_LOWER_LOSS: 2.5247\n",
      "Epoch 53000/60000, Loss: 495720.8067, WAPE: 0.1778, WAPE_TEST: 0.1754, WAPE_VOL: 0.1625, WAPE_VOL_TEST: 0.1642, reg1: 2552.2356, reg2: 1074.0108, VOL_CONS_UPPER_LOSS: 1.3752, VOL_CONS_LOWER_LOSS: 1.5778\n",
      "Epoch 53250/60000, Loss: 547426.9646, WAPE: 0.1840, WAPE_TEST: 0.1802, WAPE_VOL: 0.1706, WAPE_VOL_TEST: 0.1726, reg1: 2542.8053, reg2: 1076.6297, VOL_CONS_UPPER_LOSS: 0.1491, VOL_CONS_LOWER_LOSS: 0.9955\n",
      "Epoch 53500/60000, Loss: 606168.7661, WAPE: 0.1842, WAPE_TEST: 0.1835, WAPE_VOL: 0.1934, WAPE_VOL_TEST: 0.1999, reg1: 2723.0181, reg2: 1294.8191, VOL_CONS_UPPER_LOSS: 0.5876, VOL_CONS_LOWER_LOSS: 2.0551\n",
      "Epoch 53750/60000, Loss: 499571.6045, WAPE: 0.1773, WAPE_TEST: 0.1776, WAPE_VOL: 0.1640, WAPE_VOL_TEST: 0.1642, reg1: 2593.0739, reg2: 1143.4643, VOL_CONS_UPPER_LOSS: 0.1487, VOL_CONS_LOWER_LOSS: 1.6088\n",
      "Epoch 54000/60000, Loss: 497196.1490, WAPE: 0.1776, WAPE_TEST: 0.1774, WAPE_VOL: 0.1631, WAPE_VOL_TEST: 0.1629, reg1: 2536.6112, reg2: 1051.7878, VOL_CONS_UPPER_LOSS: 1.2002, VOL_CONS_LOWER_LOSS: 1.4840\n",
      "Epoch 54250/60000, Loss: 526803.0702, WAPE: 0.1795, WAPE_TEST: 0.1834, WAPE_VOL: 0.1695, WAPE_VOL_TEST: 0.1709, reg1: 2677.6037, reg2: 1108.9861, VOL_CONS_UPPER_LOSS: 0.7749, VOL_CONS_LOWER_LOSS: 2.3871\n",
      "Epoch 54500/60000, Loss: 500809.4118, WAPE: 0.1776, WAPE_TEST: 0.1761, WAPE_VOL: 0.1641, WAPE_VOL_TEST: 0.1640, reg1: 2552.7911, reg2: 1049.1985, VOL_CONS_UPPER_LOSS: 0.9667, VOL_CONS_LOWER_LOSS: 1.4028\n",
      "Epoch 54750/60000, Loss: 506162.0639, WAPE: 0.1781, WAPE_TEST: 0.1776, WAPE_VOL: 0.1651, WAPE_VOL_TEST: 0.1641, reg1: 2596.1244, reg2: 1105.9767, VOL_CONS_UPPER_LOSS: 3.9352, VOL_CONS_LOWER_LOSS: 1.4712\n",
      "Epoch 55000/60000, Loss: 503729.8173, WAPE: 0.1772, WAPE_TEST: 0.1789, WAPE_VOL: 0.1649, WAPE_VOL_TEST: 0.1653, reg1: 2517.1142, reg2: 1086.1978, VOL_CONS_UPPER_LOSS: 0.0486, VOL_CONS_LOWER_LOSS: 1.5278\n",
      "Epoch 55250/60000, Loss: 518210.7161, WAPE: 0.1794, WAPE_TEST: 0.1801, WAPE_VOL: 0.1643, WAPE_VOL_TEST: 0.1645, reg1: 2583.1260, reg2: 1039.1796, VOL_CONS_UPPER_LOSS: 0.0091, VOL_CONS_LOWER_LOSS: 3.4046\n",
      "Epoch 55500/60000, Loss: 496587.1987, WAPE: 0.1769, WAPE_TEST: 0.1760, WAPE_VOL: 0.1630, WAPE_VOL_TEST: 0.1618, reg1: 2542.4023, reg2: 1081.6746, VOL_CONS_UPPER_LOSS: 0.1785, VOL_CONS_LOWER_LOSS: 1.5092\n",
      "Epoch 55750/60000, Loss: 513167.6508, WAPE: 0.1779, WAPE_TEST: 0.1796, WAPE_VOL: 0.1637, WAPE_VOL_TEST: 0.1643, reg1: 2505.7098, reg2: 1070.8192, VOL_CONS_UPPER_LOSS: 0.0833, VOL_CONS_LOWER_LOSS: 1.4967\n",
      "Epoch 56000/60000, Loss: 809609.8053, WAPE: 0.1989, WAPE_TEST: 0.1896, WAPE_VOL: 0.1925, WAPE_VOL_TEST: 0.1792, reg1: 2487.2016, reg2: 1055.2278, VOL_CONS_UPPER_LOSS: 0.0330, VOL_CONS_LOWER_LOSS: 10.2330\n",
      "Epoch 56250/60000, Loss: 503780.2310, WAPE: 0.1793, WAPE_TEST: 0.1763, WAPE_VOL: 0.1642, WAPE_VOL_TEST: 0.1624, reg1: 2459.4342, reg2: 1053.5485, VOL_CONS_UPPER_LOSS: 0.3152, VOL_CONS_LOWER_LOSS: 1.4410\n",
      "Epoch 56500/60000, Loss: 556526.9394, WAPE: 0.1791, WAPE_TEST: 0.1797, WAPE_VOL: 0.1720, WAPE_VOL_TEST: 0.1689, reg1: 2589.4747, reg2: 1079.1232, VOL_CONS_UPPER_LOSS: 38.2382, VOL_CONS_LOWER_LOSS: 2.8504\n",
      "Epoch 56750/60000, Loss: 502663.9150, WAPE: 0.1774, WAPE_TEST: 0.1780, WAPE_VOL: 0.1639, WAPE_VOL_TEST: 0.1660, reg1: 2486.2729, reg2: 1071.1168, VOL_CONS_UPPER_LOSS: 5.7600, VOL_CONS_LOWER_LOSS: 1.5605\n",
      "Epoch 57000/60000, Loss: 518012.4576, WAPE: 0.1781, WAPE_TEST: 0.1789, WAPE_VOL: 0.1663, WAPE_VOL_TEST: 0.1716, reg1: 2517.6935, reg2: 1092.7758, VOL_CONS_UPPER_LOSS: 2.1488, VOL_CONS_LOWER_LOSS: 1.4222\n",
      "Epoch 57250/60000, Loss: 490982.2821, WAPE: 0.1759, WAPE_TEST: 0.1773, WAPE_VOL: 0.1615, WAPE_VOL_TEST: 0.1621, reg1: 2475.5097, reg2: 1081.3231, VOL_CONS_UPPER_LOSS: 0.3453, VOL_CONS_LOWER_LOSS: 1.5770\n",
      "Epoch 57500/60000, Loss: 518476.2201, WAPE: 0.1791, WAPE_TEST: 0.1807, WAPE_VOL: 0.1694, WAPE_VOL_TEST: 0.1711, reg1: 2482.8976, reg2: 1110.0550, VOL_CONS_UPPER_LOSS: 0.0109, VOL_CONS_LOWER_LOSS: 4.7999\n",
      "Epoch 57750/60000, Loss: 517226.6809, WAPE: 0.1800, WAPE_TEST: 0.1845, WAPE_VOL: 0.1692, WAPE_VOL_TEST: 0.1719, reg1: 2546.0689, reg2: 1115.8469, VOL_CONS_UPPER_LOSS: 2.6831, VOL_CONS_LOWER_LOSS: 3.1751\n",
      "Epoch 58000/60000, Loss: 521009.8570, WAPE: 0.1867, WAPE_TEST: 0.1879, WAPE_VOL: 0.1755, WAPE_VOL_TEST: 0.1770, reg1: 2948.7586, reg2: 1096.6135, VOL_CONS_UPPER_LOSS: 0.0149, VOL_CONS_LOWER_LOSS: 2.4369\n",
      "Epoch 58250/60000, Loss: 492395.1158, WAPE: 0.1753, WAPE_TEST: 0.1758, WAPE_VOL: 0.1610, WAPE_VOL_TEST: 0.1611, reg1: 2593.7219, reg2: 1139.0851, VOL_CONS_UPPER_LOSS: 0.5321, VOL_CONS_LOWER_LOSS: 1.4618\n",
      "Epoch 58500/60000, Loss: 515970.6831, WAPE: 0.1794, WAPE_TEST: 0.1772, WAPE_VOL: 0.1648, WAPE_VOL_TEST: 0.1611, reg1: 2566.6494, reg2: 1091.8448, VOL_CONS_UPPER_LOSS: 0.0176, VOL_CONS_LOWER_LOSS: 1.5293\n",
      "Epoch 58750/60000, Loss: 538382.3088, WAPE: 0.1744, WAPE_TEST: 0.1788, WAPE_VOL: 0.1650, WAPE_VOL_TEST: 0.1652, reg1: 2518.6624, reg2: 1067.7300, VOL_CONS_UPPER_LOSS: 29.0145, VOL_CONS_LOWER_LOSS: 1.6200\n",
      "Epoch 59000/60000, Loss: 514869.9095, WAPE: 0.1776, WAPE_TEST: 0.1776, WAPE_VOL: 0.1687, WAPE_VOL_TEST: 0.1701, reg1: 2581.6109, reg2: 1074.3294, VOL_CONS_UPPER_LOSS: 2.4233, VOL_CONS_LOWER_LOSS: 1.1763\n",
      "Epoch 59250/60000, Loss: 504728.1173, WAPE: 0.1758, WAPE_TEST: 0.1753, WAPE_VOL: 0.1627, WAPE_VOL_TEST: 0.1631, reg1: 2508.0721, reg2: 1162.2270, VOL_CONS_UPPER_LOSS: 0.6226, VOL_CONS_LOWER_LOSS: 1.7768\n",
      "Epoch 59500/60000, Loss: 498671.2631, WAPE: 0.1756, WAPE_TEST: 0.1773, WAPE_VOL: 0.1637, WAPE_VOL_TEST: 0.1657, reg1: 2507.4576, reg2: 1098.1404, VOL_CONS_UPPER_LOSS: 0.0247, VOL_CONS_LOWER_LOSS: 1.6080\n",
      "Epoch 59750/60000, Loss: 519566.8837, WAPE: 0.1779, WAPE_TEST: 0.1829, WAPE_VOL: 0.1722, WAPE_VOL_TEST: 0.1730, reg1: 2493.8378, reg2: 1063.9206, VOL_CONS_UPPER_LOSS: 6.0341, VOL_CONS_LOWER_LOSS: 2.1130\n",
      "Epoch 60000/60000, Loss: 519586.9730, WAPE: 0.1773, WAPE_TEST: 0.1765, WAPE_VOL: 0.1645, WAPE_VOL_TEST: 0.1647, reg1: 2496.2072, reg2: 1055.2887, VOL_CONS_UPPER_LOSS: 0.5517, VOL_CONS_LOWER_LOSS: 2.0733\n"
     ]
    }
   ],
   "source": [
    "metric_update_track = {\n",
    "    \"epoch\" : [],\n",
    "    \"actual_wape\" : [],\n",
    "    \"test_wape\" : [],\n",
    "    \"loss\" : [],\n",
    "    \"mse\" : [],\n",
    "    \"reg1\" : [],\n",
    "    \"reg2\" : []\n",
    "}\n",
    "\n",
    "# train model\n",
    "num_epochs = 60000\n",
    "for epoch in range(num_epochs):\n",
    "    (\n",
    "        _,\n",
    "        current_loss,\n",
    "        current_wape,\n",
    "        # current_mse,\n",
    "        current_wape_vol,\n",
    "        # current_mse_vol,\n",
    "        current_reg1,\n",
    "        current_reg2,\n",
    "        current_volume_sku_constraint_upper_loss,\n",
    "        current_volume_sku_constraint_lower_loss,\n",
    "\n",
    "    )= sess.run([\n",
    "        train,\n",
    "        loss,\n",
    "        actual_wape,\n",
    "        # total_mse,\n",
    "        actual_wape_vol,\n",
    "        # total_mse_vol,\n",
    "        reg1,\n",
    "        reg2,\n",
    "        volume_sku_constraint_upper_loss,\n",
    "        volume_sku_constraint_lower_loss,\n",
    "\n",
    "    ], feed_dict1)\n",
    "\n",
    "    current_wape_test, current_wape_vol_test = sess.run([actual_wape, actual_wape_vol], feed_dict1)\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {current_loss:.4f}, WAPE: {current_wape:.4f}, WAPE_TEST: {current_wape_test:.4f}, WAPE_VOL: {current_wape_vol:.4f}, WAPE_VOL_TEST: {current_wape_vol_test:.4f}, reg1: {current_reg1:.4f}, reg2: {current_reg2:.4f}, VOL_CONS_UPPER_LOSS: {current_volume_sku_constraint_upper_loss:.4f}, VOL_CONS_LOWER_LOSS: {current_volume_sku_constraint_lower_loss:.4f}\")\n",
    "        # metric_update_track[\"epoch\"].append(epoch)\n",
    "        # metric_update_track[\"actual_wape\"].append(current_wape)\n",
    "        # metric_update_track[\"test_wape\"].append(current_wape_test)\n",
    "        # metric_update_track[\"loss\"].append(current_loss)\n",
    "        # metric_update_track[\"mse\"].append(current_mse)\n",
    "        # metric_update_track[\"reg1\"].append(current_reg1)\n",
    "        # metric_update_track[\"reg2\"].append(current_reg2)\n",
    "\n",
    "\n",
    "\n",
    "#         # Training loop\n",
    "# num_epochs = 500\n",
    "# for epoch in range(num_epochs):\n",
    "#     _, current_error, cuurent_mse, current_m1, current_m2, current_c = sess.run([train_op, error, mse_error, m1, m2, c])\n",
    "#     if (epoch + 1) % 25 == 0:\n",
    "#         print(f\"Epoch {epoch + 1}/{num_epochs}, Error: {current_error:.4f}, MSE: {cuurent_mse:.4f}, m1: {current_m1}, m2: {current_m2}, c: {current_c}\")\n",
    "\n",
    "# # Print the final results for 'm' and 'c'\n",
    "# final_m1, final_m2, final_c = sess.run([m1, m2, c])\n",
    "# print(f\"Final 'm1' value: {final_m1}\")\n",
    "\n",
    "# print(f\"Final 'm2' value: {final_m2}\")\n",
    "# print(f\"Final 'c' value: {final_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/80000, Loss: 113523631.1456, ROI: -1.4258, BRAND_LOSS: 289.6229, PACK_LOSS: 14.1913, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.4670, NEGATIVE_LOSS: 829.2596\n",
      "Epoch 500/80000, Loss: 75899585.4421, ROI: -0.6549, BRAND_LOSS: 81.7292, PACK_LOSS: 6.3827, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.4757, NEGATIVE_LOSS: 668.7134\n",
      "Epoch 750/80000, Loss: 63113660.3536, ROI: -0.3171, BRAND_LOSS: 51.4347, PACK_LOSS: 7.0079, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.4886, NEGATIVE_LOSS: 570.5116\n",
      "Epoch 1000/80000, Loss: 56497133.2793, ROI: -0.1126, BRAND_LOSS: 45.5163, PACK_LOSS: 6.8781, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5043, NEGATIVE_LOSS: 510.3798\n",
      "Epoch 1250/80000, Loss: 52425341.4287, ROI: 0.0592, BRAND_LOSS: 42.2287, PACK_LOSS: 6.6369, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5220, NEGATIVE_LOSS: 473.1741\n",
      "Epoch 1500/80000, Loss: 49435388.6346, ROI: 0.2187, BRAND_LOSS: 39.3186, PACK_LOSS: 6.3832, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5410, NEGATIVE_LOSS: 446.4206\n",
      "Epoch 1750/80000, Loss: 46864359.3637, ROI: 0.3736, BRAND_LOSS: 36.6803, PACK_LOSS: 6.1252, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5603, NEGATIVE_LOSS: 423.5886\n",
      "Epoch 2000/80000, Loss: 44439681.2005, ROI: 0.5301, BRAND_LOSS: 34.2898, PACK_LOSS: 5.8647, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5792, NEGATIVE_LOSS: 401.9755\n",
      "Epoch 2250/80000, Loss: 42065713.5660, ROI: 0.6740, BRAND_LOSS: 32.1041, PACK_LOSS: 5.6019, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.5971, NEGATIVE_LOSS: 380.6679\n",
      "Epoch 2500/80000, Loss: 39716692.8213, ROI: 0.8058, BRAND_LOSS: 30.0780, PACK_LOSS: 5.3365, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6133, NEGATIVE_LOSS: 359.4543\n",
      "Epoch 2750/80000, Loss: 37391527.3050, ROI: 0.9339, BRAND_LOSS: 28.1737, PACK_LOSS: 5.0680, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6274, NEGATIVE_LOSS: 338.3630\n",
      "Epoch 3000/80000, Loss: 35097725.5850, ROI: 1.0586, BRAND_LOSS: 26.3633, PACK_LOSS: 4.7965, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6392, NEGATIVE_LOSS: 317.4968\n",
      "Epoch 3250/80000, Loss: 32845918.4715, ROI: 1.1752, BRAND_LOSS: 24.6295, PACK_LOSS: 4.5230, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6487, NEGATIVE_LOSS: 296.9783\n",
      "Epoch 3500/80000, Loss: 30647664.9699, ROI: 1.2847, BRAND_LOSS: 22.9638, PACK_LOSS: 4.2493, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6560, NEGATIVE_LOSS: 276.9297\n",
      "Epoch 3750/80000, Loss: 28514293.7721, ROI: 1.3883, BRAND_LOSS: 21.3638, PACK_LOSS: 3.9778, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6614, NEGATIVE_LOSS: 257.4640\n",
      "Epoch 4000/80000, Loss: 26456128.0812, ROI: 1.4877, BRAND_LOSS: 19.8308, PACK_LOSS: 3.7106, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6654, NEGATIVE_LOSS: 238.6804\n",
      "Epoch 4250/80000, Loss: 24481719.6888, ROI: 1.6234, BRAND_LOSS: 18.3593, PACK_LOSS: 3.4500, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6684, NEGATIVE_LOSS: 220.6680\n",
      "Epoch 4500/80000, Loss: 22593262.5494, ROI: 1.7354, BRAND_LOSS: 16.9391, PACK_LOSS: 3.1961, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6708, NEGATIVE_LOSS: 203.4575\n",
      "Epoch 4750/80000, Loss: 20795048.6023, ROI: 1.8237, BRAND_LOSS: 15.5970, PACK_LOSS: 2.9503, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6727, NEGATIVE_LOSS: 187.0634\n",
      "Epoch 5000/80000, Loss: 19091819.6277, ROI: 1.9056, BRAND_LOSS: 14.3357, PACK_LOSS: 2.7137, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6745, NEGATIVE_LOSS: 171.5294\n",
      "Epoch 5250/80000, Loss: 17486602.2534, ROI: 1.9824, BRAND_LOSS: 13.1567, PACK_LOSS: 2.4873, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6762, NEGATIVE_LOSS: 156.8831\n",
      "Epoch 5500/80000, Loss: 15980908.6230, ROI: 2.0464, BRAND_LOSS: 12.0602, PACK_LOSS: 2.2717, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6778, NEGATIVE_LOSS: 143.1385\n",
      "Epoch 5750/80000, Loss: 14574886.1633, ROI: 2.0889, BRAND_LOSS: 11.0451, PACK_LOSS: 2.0677, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6793, NEGATIVE_LOSS: 130.2971\n",
      "Epoch 6000/80000, Loss: 13265924.7583, ROI: 2.1360, BRAND_LOSS: 10.1092, PACK_LOSS: 1.8755, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6658, NEGATIVE_LOSS: 118.3502\n",
      "Epoch 6250/80000, Loss: 12050231.8768, ROI: 2.1782, BRAND_LOSS: 9.2527, PACK_LOSS: 1.6856, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6239, NEGATIVE_LOSS: 107.2828\n",
      "Epoch 6500/80000, Loss: 10918202.0746, ROI: 2.2173, BRAND_LOSS: 8.4703, PACK_LOSS: 1.4945, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6921, VOL_CONS_LOWER_LOSS: 1.6255, NEGATIVE_LOSS: 96.9354\n",
      "Epoch 6750/80000, Loss: 9855730.3571, ROI: 2.2494, BRAND_LOSS: 7.7423, PACK_LOSS: 1.3092, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6272, NEGATIVE_LOSS: 87.2232\n",
      "Epoch 7000/80000, Loss: 8863182.4303, ROI: 2.2785, BRAND_LOSS: 7.0642, PACK_LOSS: 1.1354, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6289, NEGATIVE_LOSS: 78.1489\n",
      "Epoch 7250/80000, Loss: 7939717.6861, ROI: 2.3031, BRAND_LOSS: 6.4334, PACK_LOSS: 0.9739, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6306, NEGATIVE_LOSS: 69.7058\n",
      "Epoch 7500/80000, Loss: 7084032.9831, ROI: 2.3289, BRAND_LOSS: 5.8467, PACK_LOSS: 0.8252, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6323, NEGATIVE_LOSS: 61.8835\n",
      "Epoch 7750/80000, Loss: 6294505.3211, ROI: 2.3362, BRAND_LOSS: 5.3013, PACK_LOSS: 0.6901, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6340, NEGATIVE_LOSS: 54.6677\n",
      "Epoch 8000/80000, Loss: 5569002.4698, ROI: 2.3602, BRAND_LOSS: 4.7940, PACK_LOSS: 0.5682, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6356, NEGATIVE_LOSS: 48.0413\n",
      "Epoch 8250/80000, Loss: 4905077.2197, ROI: 2.3639, BRAND_LOSS: 4.3222, PACK_LOSS: 0.4597, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6372, NEGATIVE_LOSS: 41.9813\n",
      "Epoch 8500/80000, Loss: 4300809.2398, ROI: 2.3735, BRAND_LOSS: 3.8833, PACK_LOSS: 0.3645, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 1.6389, NEGATIVE_LOSS: 36.4719\n",
      "Epoch 8750/80000, Loss: 3753791.4468, ROI: 2.3616, BRAND_LOSS: 3.4751, PACK_LOSS: 0.2823, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 1.6404, NEGATIVE_LOSS: 31.4908\n",
      "Epoch 9000/80000, Loss: 3124077.7676, ROI: 2.4154, BRAND_LOSS: 3.0958, PACK_LOSS: 0.2125, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2690, NEGATIVE_LOSS: 27.0160\n",
      "Epoch 9250/80000, Loss: 2683283.3817, ROI: 2.4080, BRAND_LOSS: 2.7437, PACK_LOSS: 0.1548, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2705, NEGATIVE_LOSS: 23.0168\n",
      "Epoch 9500/80000, Loss: 2292523.2765, ROI: 2.3883, BRAND_LOSS: 2.4181, PACK_LOSS: 0.1081, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6963, VOL_CONS_LOWER_LOSS: 0.2719, NEGATIVE_LOSS: 19.4760\n",
      "Epoch 9750/80000, Loss: 1947712.2173, ROI: 2.3814, BRAND_LOSS: 2.1178, PACK_LOSS: 0.0717, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2732, NEGATIVE_LOSS: 16.3679\n",
      "Epoch 10000/80000, Loss: 1646891.2987, ROI: 2.3556, BRAND_LOSS: 1.8418, PACK_LOSS: 0.0441, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2744, NEGATIVE_LOSS: 13.6620\n",
      "Epoch 10250/80000, Loss: 1385965.5155, ROI: 2.3598, BRAND_LOSS: 1.5893, PACK_LOSS: 0.0247, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2756, NEGATIVE_LOSS: 11.3241\n",
      "Epoch 10500/80000, Loss: 1162002.4847, ROI: 2.3270, BRAND_LOSS: 1.3594, PACK_LOSS: 0.0120, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2766, NEGATIVE_LOSS: 9.3260\n",
      "Epoch 10750/80000, Loss: 970993.8538, ROI: 2.3067, BRAND_LOSS: 1.1515, PACK_LOSS: 0.0045, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2776, NEGATIVE_LOSS: 7.6306\n",
      "Epoch 11000/80000, Loss: 808923.8787, ROI: 2.3063, BRAND_LOSS: 0.9640, PACK_LOSS: 0.0010, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2784, NEGATIVE_LOSS: 6.2005\n",
      "Epoch 11250/80000, Loss: 671901.6576, ROI: 2.2811, BRAND_LOSS: 0.7970, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2790, NEGATIVE_LOSS: 4.9973\n",
      "Epoch 11500/80000, Loss: 552207.4997, ROI: 2.3534, BRAND_LOSS: 0.6363, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 3.9882\n",
      "Epoch 11750/80000, Loss: 451098.5488, ROI: 2.3666, BRAND_LOSS: 0.4973, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 3.1167\n",
      "Epoch 12000/80000, Loss: 365458.0496, ROI: 2.3650, BRAND_LOSS: 0.3797, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 2.3779\n",
      "Epoch 12250/80000, Loss: 294664.7097, ROI: 2.3797, BRAND_LOSS: 0.2823, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 1.7683\n",
      "Epoch 12500/80000, Loss: 237395.6770, ROI: 2.4005, BRAND_LOSS: 0.2036, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 1.2750\n",
      "Epoch 12750/80000, Loss: 192744.2483, ROI: 2.4018, BRAND_LOSS: 0.1420, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.8900\n",
      "Epoch 13000/80000, Loss: 158484.2886, ROI: 2.4189, BRAND_LOSS: 0.0952, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.5952\n",
      "Epoch 13250/80000, Loss: 133738.1626, ROI: 2.4152, BRAND_LOSS: 0.0610, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.3815\n",
      "Epoch 13500/80000, Loss: 117312.6240, ROI: 2.4257, BRAND_LOSS: 0.0372, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.2416\n",
      "Epoch 13750/80000, Loss: 105152.4057, ROI: 2.4345, BRAND_LOSS: 0.0214, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.1359\n",
      "Epoch 14000/80000, Loss: 97693.3655, ROI: 2.4267, BRAND_LOSS: 0.0116, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0716\n",
      "Epoch 14250/80000, Loss: 93579.1637, ROI: 2.4313, BRAND_LOSS: 0.0060, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0364\n",
      "Epoch 14500/80000, Loss: 91518.8415, ROI: 2.4494, BRAND_LOSS: 0.0030, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0194\n",
      "Epoch 14750/80000, Loss: 90459.7495, ROI: 2.4522, BRAND_LOSS: 0.0015, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2540, NEGATIVE_LOSS: 0.0101\n",
      "Epoch 15000/80000, Loss: 89826.5631, ROI: 2.4493, BRAND_LOSS: 0.0009, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0052\n",
      "Epoch 15250/80000, Loss: 89620.8541, ROI: 2.4542, BRAND_LOSS: 0.0007, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 15500/80000, Loss: 89716.1970, ROI: 2.4633, BRAND_LOSS: 0.0007, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0054\n",
      "Epoch 15750/80000, Loss: 89670.1398, ROI: 2.4446, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0048\n",
      "Epoch 16000/80000, Loss: 89464.0686, ROI: 2.4243, BRAND_LOSS: 0.0011, PACK_LOSS: 0.0001, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.2539, NEGATIVE_LOSS: 0.0019\n",
      "Epoch 16250/80000, Loss: 90596.7555, ROI: 2.4484, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0167\n",
      "Epoch 16500/80000, Loss: 89855.1976, ROI: 2.4510, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0098\n",
      "Epoch 16750/80000, Loss: 89244.3404, ROI: 2.4562, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 17000/80000, Loss: 89058.8401, ROI: 2.4880, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 17250/80000, Loss: 88613.9230, ROI: 2.5349, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 17500/80000, Loss: 88670.8896, ROI: 2.5550, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0054\n",
      "Epoch 17750/80000, Loss: 88718.1320, ROI: 2.5381, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0063\n",
      "Epoch 18000/80000, Loss: 88584.0693, ROI: 2.5435, BRAND_LOSS: 0.0007, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0047\n",
      "Epoch 18250/80000, Loss: 88390.5197, ROI: 2.5847, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 18500/80000, Loss: 88766.3895, ROI: 2.5836, BRAND_LOSS: 0.0011, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0069\n",
      "Epoch 18750/80000, Loss: 88321.3493, ROI: 2.5999, BRAND_LOSS: 0.0008, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 19000/80000, Loss: 88556.2927, ROI: 2.5935, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0064\n",
      "Epoch 19250/80000, Loss: 88397.7276, ROI: 2.6288, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6927, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0051\n",
      "Epoch 19500/80000, Loss: 88487.7615, ROI: 2.6475, BRAND_LOSS: 0.0008, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0065\n",
      "Epoch 19750/80000, Loss: 88771.4621, ROI: 2.6484, BRAND_LOSS: 0.0007, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0093\n",
      "Epoch 20000/80000, Loss: 88286.4995, ROI: 2.6598, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 20250/80000, Loss: 88444.0109, ROI: 2.6750, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0069\n",
      "Epoch 20500/80000, Loss: 88261.9958, ROI: 2.6524, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0045\n",
      "Epoch 20750/80000, Loss: 88104.4098, ROI: 2.6972, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 21000/80000, Loss: 88214.2255, ROI: 2.6989, BRAND_LOSS: 0.0012, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0047\n",
      "Epoch 21250/80000, Loss: 88284.9766, ROI: 2.7074, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0063\n",
      "Epoch 21500/80000, Loss: 87826.7487, ROI: 2.7255, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 21750/80000, Loss: 87999.9973, ROI: 2.7315, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 22000/80000, Loss: 87977.0951, ROI: 2.7424, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 22250/80000, Loss: 87927.3082, ROI: 2.7653, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 22500/80000, Loss: 87829.0807, ROI: 2.7799, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0030\n",
      "Epoch 22750/80000, Loss: 87719.9099, ROI: 2.7910, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2533, NEGATIVE_LOSS: 0.0023\n",
      "Epoch 23000/80000, Loss: 87915.0624, ROI: 2.8196, BRAND_LOSS: 0.0008, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2526, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 23250/80000, Loss: 87739.9862, ROI: 2.8345, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0041\n",
      "Epoch 23500/80000, Loss: 88153.3518, ROI: 2.8289, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0078\n",
      "Epoch 23750/80000, Loss: 87699.6307, ROI: 2.8582, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 24000/80000, Loss: 87636.6141, ROI: 2.8561, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 24250/80000, Loss: 87845.8900, ROI: 2.8517, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0055\n",
      "Epoch 24500/80000, Loss: 87552.1366, ROI: 2.8701, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 24750/80000, Loss: 88063.7527, ROI: 2.8765, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0076\n",
      "Epoch 25000/80000, Loss: 87684.3977, ROI: 2.8997, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2528, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 25250/80000, Loss: 87614.7308, ROI: 2.8964, BRAND_LOSS: 0.0009, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2525, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 25500/80000, Loss: 87556.7806, ROI: 2.9184, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 25750/80000, Loss: 87600.0432, ROI: 2.9131, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0044\n",
      "Epoch 26000/80000, Loss: 87738.4684, ROI: 2.9094, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0059\n",
      "Epoch 26250/80000, Loss: 87354.0949, ROI: 2.9258, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0027\n",
      "Epoch 26500/80000, Loss: 87475.6310, ROI: 2.9294, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 26750/80000, Loss: 87554.4950, ROI: 2.9536, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 27000/80000, Loss: 87587.9287, ROI: 2.9554, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0051\n",
      "Epoch 27250/80000, Loss: 87322.7195, ROI: 2.9369, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 27500/80000, Loss: 87316.7396, ROI: 2.9675, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 27750/80000, Loss: 87375.5696, ROI: 2.9723, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 28000/80000, Loss: 87413.0124, ROI: 3.0004, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 28250/80000, Loss: 87222.8840, ROI: 2.9831, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 28500/80000, Loss: 87282.0675, ROI: 2.9934, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0030\n",
      "Epoch 28750/80000, Loss: 87423.0904, ROI: 2.9984, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 29000/80000, Loss: 87321.7417, ROI: 2.9777, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 29250/80000, Loss: 87347.3939, ROI: 2.9954, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 29500/80000, Loss: 87346.6153, ROI: 2.9829, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 29750/80000, Loss: 87698.9677, ROI: 2.9899, BRAND_LOSS: 0.0007, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0067\n",
      "Epoch 30000/80000, Loss: 87432.6112, ROI: 2.9822, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 30250/80000, Loss: 87426.7868, ROI: 2.9906, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 30500/80000, Loss: 87573.4406, ROI: 2.9980, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0053\n",
      "Epoch 30750/80000, Loss: 87252.1127, ROI: 3.0143, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 31000/80000, Loss: 87264.2951, ROI: 3.0134, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 31250/80000, Loss: 87850.4987, ROI: 2.9703, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0078\n",
      "Epoch 31500/80000, Loss: 87661.3948, ROI: 3.0024, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0062\n",
      "Epoch 31750/80000, Loss: 87298.3196, ROI: 2.9698, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0028\n",
      "Epoch 32000/80000, Loss: 87183.9083, ROI: 3.0037, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 32250/80000, Loss: 87521.0030, ROI: 3.0079, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0055\n",
      "Epoch 32500/80000, Loss: 87282.7822, ROI: 3.0015, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 32750/80000, Loss: 87527.2352, ROI: 2.9938, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 33000/80000, Loss: 87895.0719, ROI: 2.9982, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6928, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0083\n",
      "Epoch 33250/80000, Loss: 87404.1004, ROI: 2.9982, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 33500/80000, Loss: 87190.9200, ROI: 3.0196, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2529, NEGATIVE_LOSS: 0.0023\n",
      "Epoch 33750/80000, Loss: 87262.8035, ROI: 2.9993, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 34000/80000, Loss: 87785.5968, ROI: 3.0128, BRAND_LOSS: 0.0008, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.2528, NEGATIVE_LOSS: 0.0077\n",
      "Epoch 34250/80000, Loss: 87613.7092, ROI: 3.0244, BRAND_LOSS: 0.0010, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.2527, NEGATIVE_LOSS: 0.0056\n",
      "Epoch 34500/80000, Loss: 61930.0328, ROI: 2.9994, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0015\n",
      "Epoch 34750/80000, Loss: 61961.8822, ROI: 3.0102, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 35000/80000, Loss: 62165.0392, ROI: 3.0449, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 35250/80000, Loss: 61945.5994, ROI: 3.0457, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 35500/80000, Loss: 62055.3095, ROI: 3.0299, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 35750/80000, Loss: 62158.2656, ROI: 3.0501, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0047\n",
      "Epoch 36000/80000, Loss: 61852.7787, ROI: 3.0371, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 36250/80000, Loss: 62107.1905, ROI: 3.0448, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 36500/80000, Loss: 62312.6477, ROI: 3.0461, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0001, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0059\n",
      "Epoch 36750/80000, Loss: 61960.2686, ROI: 3.0376, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0026\n",
      "Epoch 37000/80000, Loss: 61877.9366, ROI: 3.0358, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 37250/80000, Loss: 62054.9585, ROI: 3.0581, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 37500/80000, Loss: 62619.5177, ROI: 3.0532, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0095\n",
      "Epoch 37750/80000, Loss: 61908.5124, ROI: 3.0348, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 38000/80000, Loss: 61953.8204, ROI: 3.0455, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0026\n",
      "Epoch 38250/80000, Loss: 62060.5009, ROI: 3.0482, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0041\n",
      "Epoch 38500/80000, Loss: 61738.4243, ROI: 3.0498, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0010\n",
      "Epoch 38750/80000, Loss: 61891.6256, ROI: 3.0546, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 39000/80000, Loss: 62274.3005, ROI: 2.9917, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 39250/80000, Loss: 62043.6682, ROI: 3.0414, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 39500/80000, Loss: 61862.9156, ROI: 3.0500, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0018\n",
      "Epoch 39750/80000, Loss: 61915.7949, ROI: 3.0370, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0021\n",
      "Epoch 40000/80000, Loss: 62130.1178, ROI: 3.0665, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0048\n",
      "Epoch 40250/80000, Loss: 61930.7592, ROI: 3.0544, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 40500/80000, Loss: 62134.3417, ROI: 3.0240, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 40750/80000, Loss: 62019.7484, ROI: 3.0486, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 41000/80000, Loss: 62174.0766, ROI: 3.0555, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0051\n",
      "Epoch 41250/80000, Loss: 62014.3629, ROI: 3.0416, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0032\n",
      "Epoch 41500/80000, Loss: 62214.0237, ROI: 3.0306, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 41750/80000, Loss: 62275.7702, ROI: 3.0503, BRAND_LOSS: 0.0006, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0054\n",
      "Epoch 42000/80000, Loss: 61989.8389, ROI: 3.0328, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 42250/80000, Loss: 61915.2001, ROI: 3.0536, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0021\n",
      "Epoch 42500/80000, Loss: 62105.8637, ROI: 3.0113, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 42750/80000, Loss: 62012.5370, ROI: 3.0351, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0032\n",
      "Epoch 43000/80000, Loss: 61817.7936, ROI: 3.0396, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0017\n",
      "Epoch 43250/80000, Loss: 61888.4479, ROI: 3.0506, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 43500/80000, Loss: 62186.1322, ROI: 3.0206, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 43750/80000, Loss: 61944.0603, ROI: 3.0366, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0023\n",
      "Epoch 44000/80000, Loss: 61931.8861, ROI: 3.0230, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0013\n",
      "Epoch 44250/80000, Loss: 61954.8004, ROI: 3.0340, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 44500/80000, Loss: 62158.0358, ROI: 3.0404, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0005, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0045\n",
      "Epoch 44750/80000, Loss: 61928.6025, ROI: 3.0581, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0003, SEGMENT_LOSS: 0.0003, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0026\n",
      "Epoch 45000/80000, Loss: 61989.5661, ROI: 3.0241, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 45250/80000, Loss: 62006.9045, ROI: 3.0354, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 45500/80000, Loss: 62107.5202, ROI: 3.0417, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 45750/80000, Loss: 61995.4835, ROI: 3.0107, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0023\n",
      "Epoch 46000/80000, Loss: 62003.8355, ROI: 3.0552, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0037\n",
      "Epoch 46250/80000, Loss: 62272.8389, ROI: 3.0489, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0057\n",
      "Epoch 46500/80000, Loss: 62085.1370, ROI: 3.0359, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 46750/80000, Loss: 62081.1547, ROI: 3.0496, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 47000/80000, Loss: 62386.0237, ROI: 3.0281, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0066\n",
      "Epoch 47250/80000, Loss: 62250.0219, ROI: 3.0340, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0056\n",
      "Epoch 47500/80000, Loss: 62027.0876, ROI: 3.0424, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 47750/80000, Loss: 62057.4829, ROI: 3.0411, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 48000/80000, Loss: 62216.6741, ROI: 3.0479, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0054\n",
      "Epoch 48250/80000, Loss: 62609.5820, ROI: 3.0361, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0084\n",
      "Epoch 48500/80000, Loss: 62270.2463, ROI: 3.0398, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0058\n",
      "Epoch 48750/80000, Loss: 62164.9836, ROI: 3.0368, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 49000/80000, Loss: 62120.2545, ROI: 3.0380, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 49250/80000, Loss: 61971.8026, ROI: 3.0482, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0007, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0026\n",
      "Epoch 49500/80000, Loss: 61908.7275, ROI: 3.0647, BRAND_LOSS: 0.0000, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 49750/80000, Loss: 62257.8537, ROI: 3.0412, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0053\n",
      "Epoch 50000/80000, Loss: 62137.1798, ROI: 3.0327, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 50250/80000, Loss: 61914.4564, ROI: 3.0564, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 50500/80000, Loss: 62839.7505, ROI: 3.0215, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6977, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0053\n",
      "Epoch 50750/80000, Loss: 62161.4594, ROI: 3.0395, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 51000/80000, Loss: 62137.5962, ROI: 3.0446, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 51250/80000, Loss: 62087.1215, ROI: 3.0432, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 51500/80000, Loss: 62468.8932, ROI: 3.0512, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0077\n",
      "Epoch 51750/80000, Loss: 62117.4944, ROI: 3.0477, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 52000/80000, Loss: 62444.2776, ROI: 3.0006, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6927, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0058\n",
      "Epoch 52250/80000, Loss: 62157.2350, ROI: 3.0222, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 52500/80000, Loss: 62288.1818, ROI: 3.0430, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0061\n",
      "Epoch 52750/80000, Loss: 61898.0281, ROI: 3.0668, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 53000/80000, Loss: 62127.8446, ROI: 3.0340, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 53250/80000, Loss: 62021.1534, ROI: 3.0421, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 53500/80000, Loss: 62117.2603, ROI: 3.0409, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 53750/80000, Loss: 61869.3616, ROI: 3.0603, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0019\n",
      "Epoch 54000/80000, Loss: 62109.2017, ROI: 3.0115, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0030\n",
      "Epoch 54250/80000, Loss: 62106.4827, ROI: 3.0479, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 54500/80000, Loss: 61772.9237, ROI: 3.0464, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0009\n",
      "Epoch 54750/80000, Loss: 62203.0924, ROI: 3.0356, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0052\n",
      "Epoch 55000/80000, Loss: 62234.1837, ROI: 3.0159, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 55250/80000, Loss: 62016.4451, ROI: 3.0481, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 55500/80000, Loss: 62026.9026, ROI: 3.0454, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6935, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 55750/80000, Loss: 62127.5564, ROI: 3.0503, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 56000/80000, Loss: 62148.1322, ROI: 3.0333, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 56250/80000, Loss: 62170.2044, ROI: 3.0493, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 56500/80000, Loss: 62104.8638, ROI: 3.0305, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6930, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 56750/80000, Loss: 62167.3891, ROI: 3.0313, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0041\n",
      "Epoch 57000/80000, Loss: 62290.9929, ROI: 3.0185, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 57250/80000, Loss: 61987.9774, ROI: 3.0464, BRAND_LOSS: 0.0003, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6928, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0018\n",
      "Epoch 57500/80000, Loss: 61977.8423, ROI: 3.0589, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 57750/80000, Loss: 62125.2779, ROI: 3.0627, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0048\n",
      "Epoch 58000/80000, Loss: 61921.9146, ROI: 3.0490, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 58250/80000, Loss: 62018.6774, ROI: 3.0337, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 58500/80000, Loss: 61964.5452, ROI: 3.0356, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0021\n",
      "Epoch 58750/80000, Loss: 62239.4672, ROI: 3.0447, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0050\n",
      "Epoch 59000/80000, Loss: 61754.5248, ROI: 3.0459, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0010\n",
      "Epoch 59250/80000, Loss: 61890.6226, ROI: 3.0383, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 59500/80000, Loss: 62092.5565, ROI: 3.0233, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 59750/80000, Loss: 61999.1678, ROI: 3.0399, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 60000/80000, Loss: 61894.7373, ROI: 3.0430, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 60250/80000, Loss: 62014.2155, ROI: 3.0203, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0027\n",
      "Epoch 60500/80000, Loss: 62067.6585, ROI: 3.0287, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0035\n",
      "Epoch 60750/80000, Loss: 62155.6027, ROI: 3.0224, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 61000/80000, Loss: 61884.0876, ROI: 3.0511, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0020\n",
      "Epoch 61250/80000, Loss: 61924.9571, ROI: 3.0528, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6927, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 61500/80000, Loss: 62405.5236, ROI: 3.0552, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0062\n",
      "Epoch 61750/80000, Loss: 62111.9691, ROI: 3.0294, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 62000/80000, Loss: 62051.5031, ROI: 3.0274, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 62250/80000, Loss: 62080.5624, ROI: 3.0224, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 62500/80000, Loss: 62191.5617, ROI: 3.0237, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 62750/80000, Loss: 62447.6818, ROI: 3.0343, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0067\n",
      "Epoch 63000/80000, Loss: 61985.6305, ROI: 3.0490, BRAND_LOSS: 0.0003, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0027\n",
      "Epoch 63250/80000, Loss: 62152.7607, ROI: 3.0486, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0046\n",
      "Epoch 63500/80000, Loss: 62045.4397, ROI: 3.0451, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 63750/80000, Loss: 61897.7401, ROI: 3.0391, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0002, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0012\n",
      "Epoch 64000/80000, Loss: 61964.7582, ROI: 3.0294, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 64250/80000, Loss: 62067.0307, ROI: 3.0561, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 64500/80000, Loss: 61986.2332, ROI: 3.0563, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0032\n",
      "Epoch 64750/80000, Loss: 62209.5911, ROI: 3.0631, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6956, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0027\n",
      "Epoch 65000/80000, Loss: 61911.6501, ROI: 3.0476, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0023\n",
      "Epoch 65250/80000, Loss: 62140.2778, ROI: 3.0429, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0044\n",
      "Epoch 65500/80000, Loss: 61923.4615, ROI: 3.0473, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0019\n",
      "Epoch 65750/80000, Loss: 62050.2545, ROI: 3.0222, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 66000/80000, Loss: 62291.9723, ROI: 3.0012, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 66250/80000, Loss: 61972.2814, ROI: 3.0452, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0004, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0028\n",
      "Epoch 66500/80000, Loss: 61986.0095, ROI: 3.0472, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0033\n",
      "Epoch 66750/80000, Loss: 62149.4788, ROI: 3.0432, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 67000/80000, Loss: 62347.5195, ROI: 3.0270, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0064\n",
      "Epoch 67250/80000, Loss: 62054.3371, ROI: 3.0382, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 67500/80000, Loss: 62127.5637, ROI: 3.0499, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 67750/80000, Loss: 62388.0455, ROI: 3.0284, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0067\n",
      "Epoch 68000/80000, Loss: 62072.2095, ROI: 3.0620, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0044\n",
      "Epoch 68250/80000, Loss: 62153.9231, ROI: 2.9846, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0002, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 68500/80000, Loss: 61963.4554, ROI: 3.0449, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 68750/80000, Loss: 62090.3482, ROI: 3.0330, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0041\n",
      "Epoch 69000/80000, Loss: 61983.8348, ROI: 3.0594, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0031\n",
      "Epoch 69250/80000, Loss: 61973.5813, ROI: 3.0438, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6932, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0017\n",
      "Epoch 69500/80000, Loss: 62103.9324, ROI: 3.0573, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6928, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0044\n",
      "Epoch 69750/80000, Loss: 62406.0541, ROI: 3.0199, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0063\n",
      "Epoch 70000/80000, Loss: 62281.4713, ROI: 3.0068, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6942, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0030\n",
      "Epoch 70250/80000, Loss: 61914.6202, ROI: 3.0577, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 70500/80000, Loss: 62044.6035, ROI: 3.0409, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0036\n",
      "Epoch 70750/80000, Loss: 62063.7182, ROI: 3.0429, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0040\n",
      "Epoch 71000/80000, Loss: 61989.8558, ROI: 3.0598, BRAND_LOSS: 0.0004, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 71250/80000, Loss: 61919.3896, ROI: 3.0522, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 71500/80000, Loss: 62074.4188, ROI: 3.0549, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 71750/80000, Loss: 62082.6853, ROI: 3.0564, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0041\n",
      "Epoch 72000/80000, Loss: 61889.5254, ROI: 3.0566, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 72250/80000, Loss: 62238.4716, ROI: 3.0400, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0053\n",
      "Epoch 72500/80000, Loss: 62341.6003, ROI: 3.0368, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0063\n",
      "Epoch 72750/80000, Loss: 62265.0412, ROI: 3.0475, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0059\n",
      "Epoch 73000/80000, Loss: 62236.2193, ROI: 3.0220, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 73250/80000, Loss: 62067.7025, ROI: 3.0613, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6930, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0038\n",
      "Epoch 73500/80000, Loss: 62148.7202, ROI: 3.0235, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0039\n",
      "Epoch 73750/80000, Loss: 61984.9803, ROI: 3.0364, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0025\n",
      "Epoch 74000/80000, Loss: 62337.8489, ROI: 3.0278, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6926, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0056\n",
      "Epoch 74250/80000, Loss: 62097.5005, ROI: 3.0490, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 74500/80000, Loss: 61821.7181, ROI: 3.0548, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6923, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0012\n",
      "Epoch 74750/80000, Loss: 61959.7297, ROI: 3.0297, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0001, SEGMENT_LOSS: 0.0005, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0016\n",
      "Epoch 75000/80000, Loss: 62043.2669, ROI: 3.0353, BRAND_LOSS: 0.0000, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0037\n",
      "Epoch 75250/80000, Loss: 61970.6255, ROI: 3.0639, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0034\n",
      "Epoch 75500/80000, Loss: 61926.3071, ROI: 3.0414, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0024\n",
      "Epoch 75750/80000, Loss: 62139.0735, ROI: 3.0499, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0048\n",
      "Epoch 76000/80000, Loss: 62253.4718, ROI: 3.0326, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6928, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0044\n",
      "Epoch 76250/80000, Loss: 61870.8971, ROI: 3.0719, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6929, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 76500/80000, Loss: 61949.4241, ROI: 3.0360, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0022\n",
      "Epoch 76750/80000, Loss: 62144.2423, ROI: 3.0193, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 77000/80000, Loss: 62262.4832, ROI: 3.0365, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6927, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0052\n",
      "Epoch 77250/80000, Loss: 62351.8256, ROI: 3.0068, BRAND_LOSS: 0.0002, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0049\n",
      "Epoch 77500/80000, Loss: 62039.4656, ROI: 3.0497, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6924, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0037\n",
      "Epoch 77750/80000, Loss: 62524.3547, ROI: 3.0442, BRAND_LOSS: 0.0003, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6927, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0076\n",
      "Epoch 78000/80000, Loss: 62191.2759, ROI: 3.0500, BRAND_LOSS: 0.0005, PACK_LOSS: 0.0001, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0042\n",
      "Epoch 78250/80000, Loss: 62153.8557, ROI: 3.0311, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0043\n",
      "Epoch 78500/80000, Loss: 62837.7958, ROI: 3.0748, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0021, NEGATIVE_LOSS: 0.0114\n",
      "Epoch 78750/80000, Loss: 62221.5159, ROI: 3.0668, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0001, VOL_CONS_UPPER_LOSS: 0.6925, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0054\n",
      "Epoch 79000/80000, Loss: 61995.9733, ROI: 3.0422, BRAND_LOSS: 0.0003, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0015, NEGATIVE_LOSS: 0.0026\n",
      "Epoch 79250/80000, Loss: 62367.9444, ROI: 3.0180, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0059\n",
      "Epoch 79500/80000, Loss: 62360.1827, ROI: 3.0404, BRAND_LOSS: 0.0003, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6928, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0059\n",
      "Epoch 79750/80000, Loss: 61983.9425, ROI: 3.0392, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0029\n",
      "Epoch 80000/80000, Loss: 61997.2683, ROI: 3.0283, BRAND_LOSS: 0.0001, PACK_LOSS: 0.0000, SEGMENT_LOSS: 0.0000, VOL_CONS_UPPER_LOSS: 0.6922, VOL_CONS_LOWER_LOSS: 0.0014, NEGATIVE_LOSS: 0.0028\n"
     ]
    }
   ],
   "source": [
    "metric_update_track = {\n",
    "    \"epoch\" : [],\n",
    "    \"actual_wape\" : [],\n",
    "    \"test_wape\" : [],\n",
    "    \"loss\" : [],\n",
    "    \"mse\" : [],\n",
    "    \"reg1\" : [],\n",
    "    \"reg2\" : []\n",
    "}\n",
    "\n",
    "# train model\n",
    "num_epochs = 80000\n",
    "for epoch in range(num_epochs):\n",
    "    (\n",
    "        _,\n",
    "        current_loss_roi,\n",
    "        current_roi,\n",
    "        current_brand_constraint_loss,\n",
    "        current_pack_constraint_loss,\n",
    "        current_segment_constraint_loss,\n",
    "        current_volume_sku_constraint_upper_loss,\n",
    "        current_volume_sku_constraint_lower_loss,\n",
    "        current_negative_discount_loss\n",
    "\n",
    "        # current_wape,\n",
    "        # current_mse,\n",
    "        # current_wape_vol,\n",
    "        # current_mse_vol,\n",
    "        # current_reg1,\n",
    "        # current_reg2\n",
    "    )= sess.run([\n",
    "        train_roi,\n",
    "        loss_roi,\n",
    "        roi,\n",
    "        brand_constraint_loss,\n",
    "        pack_constraint_loss,\n",
    "        segment_constraint_loss,\n",
    "        volume_sku_constraint_upper_loss,\n",
    "        volume_sku_constraint_lower_loss,\n",
    "        negative_discount_loss\n",
    "        # actual_wape,\n",
    "        # total_mse,\n",
    "        # actual_wape_vol,\n",
    "        # total_mse_vol,\n",
    "        # reg1,\n",
    "        # reg2\n",
    "    ], feed_dict1)\n",
    "\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {current_loss_roi:.4f}, ROI: {current_roi:.4f}, BRAND_LOSS: {current_brand_constraint_loss:.4f}, PACK_LOSS: {current_pack_constraint_loss:.4f}, SEGMENT_LOSS: {current_segment_constraint_loss:.4f}, VOL_CONS_UPPER_LOSS: {current_volume_sku_constraint_upper_loss:.4f}, VOL_CONS_LOWER_LOSS: {current_volume_sku_constraint_lower_loss:.4f}, NEGATIVE_LOSS: {current_negative_discount_loss:.4f}\")\n",
    "        # \")#, WAPE_TEST: {current_wape_test:.4f}, WAPE_VOL: {current_wape_vol:.4f}, WAPE_VOL_TEST: {current_wape_vol_test:.4f}, reg1: {current_reg1:.4f}, reg2: {current_reg2:.4f}\")\n",
    "        # metric_update_track[\"epoch\"].append(epoch)\n",
    "        # metric_update_track[\"actual_wape\"].append(current_wape)\n",
    "        # metric_update_track[\"test_wape\"].append(current_wape_test)\n",
    "        # metric_update_track[\"loss\"].append(current_loss)\n",
    "        # metric_update_track[\"mse\"].append(current_mse)\n",
    "        # metric_update_track[\"reg1\"].append(current_reg1)\n",
    "        # metric_update_track[\"reg2\"].append(current_reg2)\n",
    "\n",
    "\n",
    "\n",
    "#         # Training loop\n",
    "# num_epochs = 500\n",
    "# for epoch in range(num_epochs):\n",
    "#     _, current_error, cuurent_mse, current_m1, current_m2, current_c = sess.run([train_op, error, mse_error, m1, m2, c])\n",
    "#     if (epoch + 1) % 25 == 0:\n",
    "#         print(f\"Epoch {epoch + 1}/{num_epochs}, Error: {current_error:.4f}, MSE: {cuurent_mse:.4f}, m1: {current_m1}, m2: {current_m2}, c: {current_c}\")\n",
    "\n",
    "# # Print the final results for 'm' and 'c'\n",
    "# final_m1, final_m2, final_c = sess.run([m1, m2, c])\n",
    "# print(f\"Final 'm1' value: {final_m1}\")\n",
    "\n",
    "# print(f\"Final 'm2' value: {final_m2}\")\n",
    "# print(f\"Final 'c' value: {final_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_actual_submit, nr_actual_submit, vol_opt_submit, nr_opt_submit, optimal_discount = sess.run([y_initial_vol_pred, y_inital_pred, y_opt_vol_pred, y_opt_pred, discounts_var], feed_dict1)\n",
    "\n",
    "nr_actual_submit = nr_actual_submit * scaler\n",
    "vol_actual_submit = vol_actual_submit * vol_scaler\n",
    "nr_opt_submit = nr_opt_submit * scaler\n",
    "vol_opt_submit = vol_opt_submit * vol_scaler\n",
    "\n",
    "nr_data_temp = (\n",
    "    sales_data\n",
    "    .reset_index()\n",
    "    .groupby([\"date\", \"sku\"])\n",
    "    .net_revenue.sum()\n",
    "    .sort_index()\n",
    "    .unstack(1)\n",
    "    [sku_index_order]\n",
    ")\n",
    "\n",
    "nr_actual_submit = pd.DataFrame(nr_actual_submit, index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "nr_opt_submit = pd.DataFrame(nr_opt_submit, index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "vol_actual_submit = pd.DataFrame(vol_actual_submit, index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "vol_opt_submit = pd.DataFrame(vol_opt_submit, index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "promo_optimal_discount = pd.DataFrame(optimal_discount[:,:,0], index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "other_optimal_discount = pd.DataFrame(optimal_discount[:,:,1], index=nr_data_temp.index[-2:], columns=nr_data_temp.columns)\n",
    "\n",
    "submit_temp = sales_data[sales_data.gto.isna()].reset_index().set_index([\"date\", \"sku\", \"brand\", \"pack\", \"size\"]).sort_index()\n",
    "submit_temp.loc[:, \"net_revenue\"] = submit_temp.net_revenue.fillna(nr_actual_submit.stack())\n",
    "submit_temp.loc[:, \"volume\"] = submit_temp.volume.fillna(vol_actual_submit.stack())\n",
    "submit_temp.loc[:, \"net_revenue_opt\"] = submit_temp.net_revenue.fillna(nr_actual_submit.stack())\n",
    "submit_temp.loc[:, \"volume_opt\"] = submit_temp.volume.fillna(vol_actual_submit.stack())\n",
    "submit_temp.loc[:, \"promotional_discount\"] = np.nan\n",
    "submit_temp.loc[:, \"other_discounts\"] = np.nan\n",
    "submit_temp.loc[:, \"promotional_discount\"] = submit_temp.net_revenue.fillna(promo_optimal_discount.stack())\n",
    "submit_temp.loc[:, \"other_discounts\"] = submit_temp.volume.fillna(other_optimal_discount.stack())\n",
    "submit_temp = submit_temp.reset_index()\n",
    "\n",
    "\n",
    "cols_req = [ \"Year\", \"Month\", \"SKU\", \"Brand\", \"Pack\", \"Size\", \"Volume_Estimate\", \"Net_Revenue_Estimate\", \"Optimal_Promotional_Discount\", \"Optimal_Other_Discounts\", \"Optimal_Volume\", \"Optimal_Net_Revenue\"]\n",
    "\n",
    "\n",
    "submit_temp.loc[:, \"Year\"] = submit_temp.date.dt.year\n",
    "submit_temp.loc[:, \"Month\"] = submit_temp.date.dt.month\n",
    "submit_temp.loc[:, \"SKU\"] = submit_temp.sku\n",
    "submit_temp.loc[:, \"Brand\"] = submit_temp.brand\n",
    "submit_temp.loc[:, \"Pack\"] = submit_temp.pack\n",
    "submit_temp.loc[:, \"Size\"] = submit_temp[\"size\"]\n",
    "submit_temp.loc[:, \"Volume_Estimate\"] = submit_temp.volume\n",
    "submit_temp.loc[:, \"Net_Revenue_Estimate\"] = submit_temp.net_revenue\n",
    "submit_temp.loc[:, \"Optimal_Promotional_Discount\"] = submit_temp.promotional_discount\n",
    "submit_temp.loc[:, \"Optimal_Other_Discounts\"] = submit_temp.other_discounts\n",
    "submit_temp.loc[:, \"Optimal_Volume\"] = submit_temp.volume_opt\n",
    "submit_temp.loc[:, \"Optimal_Net_Revenue\"] = submit_temp.net_revenue_opt\n",
    "\n",
    "submit_temp = submit_temp[cols_req]\n",
    "submit_temp.to_csv(\"/home/akshay-development-server/promo-optimization_team-simpsons-paradox/data/team_simpsons_paradox_submission_11.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mroi_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
