{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-storage-blob\n",
    "# !pip install python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from setup_utils import fetch_data, load_data, create_time_index\n",
    "\n",
    "CONNECTION_STRING = os.getenv(\"CONNECTION_STRING\")\n",
    "\n",
    "load_dotenv()\n",
    "# fetch_data(CONNECTION_STRING)\n",
    "\n",
    "(\n",
    "    brand_mapping,\n",
    "    macro_data,\n",
    "    brand_constraint,\n",
    "    pack_constraint,\n",
    "    segment_constraint,\n",
    "    sales_data,\n",
    "    volume_variation_constraint,\n",
    ") = load_data()\n",
    "\n",
    "(\n",
    "    macro_data,\n",
    "    sales_data,\n",
    ") = create_time_index([macro_data, sales_data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as ltb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = sales_data[sales_data.volume.notna()].join(macro_data, on=\"date\", how=\"left\")\n",
    "# df_test = sales_data[sales_data.volume.isna()].join(macro_data, on=\"date\", how=\"left\")\n",
    "\n",
    "df = sales_data.join(macro_data, on=\"date\", how=\"left\")\n",
    "\n",
    "df = df[((df.gto>0) & (df.volume>0) & (df.promotional_discount<=0) & (df.other_discounts<=0)) | df.gto.isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "df_og = df.copy(deep=True)\n",
    "\n",
    "# Identify and convert categorical columns to label encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = [\"gto\", \"volume\"]\n",
    "drop_cols = [\"sku\",\"brand\",\"pack\",\"size\",\"total_discounts\",\"excise\",\"net_revenue\",\"maco\",\"vilc\"]\n",
    "X = df[df.gto.notna()].drop(columns=[*target_column] + drop_cols)\n",
    "y = df[df.gto.notna()][target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns,index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[X.index<\"2023-04-01\"]\n",
    "x_test = X[X.index>=\"2023-04-01\"]\n",
    "\n",
    "y_train = y[y.index<\"2023-04-01\"]\n",
    "y_test = y[y.index>=\"2023-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = df[df.gto.isna()].drop(columns=[*target_column])\n",
    "\n",
    "# # Define a custom scorer for Weighted Absolute Percentage Error (WAPE)\n",
    "# def wape_scorer(y_true, y_pred):\n",
    "#     weighted_absolute_percentage_errors = np.abs((y_true - y_pred) / y_true) * np.abs(y_pred)\n",
    "#     wape = np.sum(weighted_absolute_percentage_errors) / np.sum(np.abs(y_pred))\n",
    "#     return np.mean(1 - wape)  # Return 1 - WAPE as a scorer\n",
    "\n",
    "# # Create a multi-output XGBoost model\n",
    "# model = MultiOutputRegressor(xgb.XGBRegressor())\n",
    "\n",
    "# # Define the WAPE scorer using make_scorer\n",
    "# wape_scorer = make_scorer(wape_scorer, greater_is_better=True)\n",
    "\n",
    "# # Perform 5-fold cross-validation and calculate WAPE scores\n",
    "# cross_val_scores = cross_val_score(model, X, y, cv=5, scoring=wape_scorer)\n",
    "\n",
    "# # Print WAPE scores for each fold\n",
    "# for fold, score in enumerate(cross_val_scores, start=1):\n",
    "#     print(f'Fold {fold}: WAPE Score = {score:.4f}')\n",
    "\n",
    "# # Print the mean WAPE score across all folds\n",
    "# mean_wape_score = cross_val_scores.mean()\n",
    "# print(f'Mean WAPE Score across Folds = {mean_wape_score:.4f}')\n",
    "\n",
    "model = MultiOutputRegressor(xgb.XGBRegressor())\n",
    "\n",
    "# model = MultiOutputRegressor(ltb.LGBMClassifier())\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred,columns = y_test.columns,index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wape = (y_test - y_pred).abs().sum() / y_test.sum()\n",
    "print(wape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def custom_objective(promo_discount, X, model, X_test, X_test_new):\n",
    "    # Create a copy of X with the promo_discount column replaced\n",
    "    X_modified = X.copy()\n",
    "    X_modified[:, promo_column_index] = promo_discount\n",
    "\n",
    "    # Predict using the modified X on the test set\n",
    "    predictions_new = model.predict(X_test_new)\n",
    "\n",
    "    # Predict using the modified X on the original test set\n",
    "    predictions_original = model.predict(X_test)\n",
    "\n",
    "    # Calculate the objective function value\n",
    "    objective_value = -((predictions_new.sum() - predictions_original.sum()) / X_test.sum())\n",
    "\n",
    "    return objective_value\n",
    "\n",
    "# Replace these with your actual data and model\n",
    "X = ...  # Your input data (including promo_discount column)\n",
    "Y = ...  # Your target variables\n",
    "X_test_new = ...  # New test data\n",
    "X_test = ...  # Original test data\n",
    "model = ...  # Your machine learning model\n",
    "\n",
    "# Identify the column index for 'promo_discount' in X\n",
    "promo_column_index = X.columns.get_loc('promo_discount')\n",
    "\n",
    "# Initialize the initial guess for promo_discount\n",
    "initial_guess = 0.1  # Replace with your initial value\n",
    "\n",
    "# Define the optimization bounds for promo_discount (e.g., between 0 and 1)\n",
    "bounds = [(0, 1)]\n",
    "\n",
    "# Optimize promo_discount to maximize the objective function\n",
    "result = minimize(custom_objective, initial_guess, args=(X.values, model, X_test.values, X_test_new.values),\n",
    "                  bounds=bounds, method='L-BFGS-B')\n",
    "\n",
    "# Extract the optimized promo_discount\n",
    "optimized_promo_discount = result.x[0]\n",
    "\n",
    "# Print the optimized promo_discount value\n",
    "print(f'Optimized Promo Discount: {optimized_promo_discount:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\40107702\\Documents\\PyMMM\\mroi-ml-lib\\data\\hackathon\\raw\\hackathon_macroeconomics_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\40107702\\Documents\\PyMMM\\mroi-ml-lib\\data\\hackathon\\raw\\hackathon_macroeconomics_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
